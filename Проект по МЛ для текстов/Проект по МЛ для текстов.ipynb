{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5b26e3",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bfe8f",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Требуется обучить модель и классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acad29",
   "metadata": {},
   "source": [
    "## Подготовка к работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53afc3",
   "metadata": {},
   "source": [
    "Установим все требуемые для выполнения проектной работы фреймворки и библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b73186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cea10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: requests in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e031811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: detoxify in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from detoxify) (1.12.0)\n",
      "Requirement already satisfied: transformers!=4.18.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from detoxify) (4.20.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.94 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from detoxify) (0.1.96)\n",
      "Requirement already satisfied: typing-extensions in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.7.0->detoxify) (3.10.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (1.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (2021.8.3)\n",
      "Requirement already satisfied: requests in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (21.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from transformers!=4.18.0->detoxify) (3.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers!=4.18.0->detoxify) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers!=4.18.0->detoxify) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers!=4.18.0->detoxify) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers!=4.18.0->detoxify) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers!=4.18.0->detoxify) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96e924a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alex/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from catboost import CatBoostClassifier\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from transformers import AutoModel\n",
    "from detoxify import Detoxify\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0060931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузим данные\n",
    "df = pd.read_csv('toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ознакомимся\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa05460",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Извлечем корпус\n",
    "corpus = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Напишем функцию очистки текста при помощи регулярных выражений\n",
    "def clean_text(text):\n",
    "    txt_after_sub = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    return \" \".join(txt_after_sub.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Напишем функцию для получения POS-тегов для лемматизатора WordNet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\":wordnet.ADJ,\n",
    "                \"V\":wordnet.VERB,\n",
    "                \"R\":wordnet.ADV,\n",
    "                \"N\":wordnet.NOUN}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Собственно сам лемматизатор с разбивкой текста на токены внутри\n",
    "Lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    lemm_text = ' '.join([Lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokenized_text])\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим новый столбец в исходном датасете с лемматизированным и очищенным текстом\n",
    "df['lemm'] = pd.Series(corpus).apply(lambda x: lemmatizer(clean_text(x)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Скачаем датасет для того чтобы не проделывать заново предобработку в случае если ядро отвалится\n",
    "df.to_csv('df_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cd386c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Загрузка датасета на случай если всё пошло не так:)\n",
    "df = pd.read_csv('df_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf02d7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "lemm          7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e938157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aacd60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "lemm          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4add795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определим фичи и таргет, а затем поделим их на тестовые и обучающие\n",
    "features = df['lemm'].values\n",
    "target = df['toxic'].values\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=.25, random_state=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8068161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11d4dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Посчитаем Tfidf с указанными стоп словами, затем обучим векторайзер и преобразуем им фичи\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('english'))\n",
    "count_tfidf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "\n",
    "tfidf_train = count_tfidf.fit_transform(features_train)\n",
    "tfidf_test = count_tfidf.fit(features_train, target_train)\n",
    "tfidf_test = count_tfidf.transform(features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb4d12",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров и обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573e463",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8bf4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7622499134216033\n",
      "Best params: {'tfidf__ngram_range': (1, 1), 'clf__random_state': 12, 'clf__max_iter': 641, 'clf__C': 4}\n"
     ]
    }
   ],
   "source": [
    "#Подберем гиперпараметры для логистической регрессии при помощи RandomizedSearch'а\n",
    "#поскольку метод имеет внутри кросс-валидацию, выделять данные на валидацию не будем\n",
    "model_LR = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression())\n",
    "                    ])\n",
    "params = {'tfidf__ngram_range':((1,1),(1,2)),\n",
    "          'clf__C':range(1,5),\n",
    "         'clf__max_iter':range(1,1000,20),\n",
    "         'clf__random_state':[12]}\n",
    "rand_search = RandomizedSearchCV(pipeline, param_distributions=params, scoring='f1', n_jobs=-1, verbose=1)\n",
    "rand_search.fit(features_train, target_train)\n",
    "print(f'Best score: {rand_search.best_score_}')\n",
    "print(f'Best params: {rand_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd77f59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7809990472301619"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#а теперь то же самое на тестовой выборке\n",
    "model_LR = LogisticRegression(random_state=12, max_iter=641, C=4, solver='liblinear', penalty='l1')\n",
    "model_LR.fit(tfidf_train, target_train)\n",
    "predictions = model_LR.predict(tfidf_test)\n",
    "\n",
    "\n",
    "f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d41819",
   "metadata": {},
   "source": [
    "**Отлично, сразу получилась проходная метрика, теперь попробуем другие алгоритмы.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3512874",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92f5f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5479700\ttotal: 504ms\tremaining: 8m 23s\n",
      "1:\tlearn: 0.4478161\ttotal: 860ms\tremaining: 7m 8s\n",
      "2:\tlearn: 0.3810655\ttotal: 1.2s\tremaining: 6m 39s\n",
      "3:\tlearn: 0.3342243\ttotal: 1.55s\tremaining: 6m 25s\n",
      "4:\tlearn: 0.3023466\ttotal: 1.9s\tremaining: 6m 18s\n",
      "5:\tlearn: 0.2813762\ttotal: 2.26s\tremaining: 6m 15s\n",
      "6:\tlearn: 0.2663177\ttotal: 2.63s\tremaining: 6m 13s\n",
      "7:\tlearn: 0.2548055\ttotal: 3.01s\tremaining: 6m 13s\n",
      "8:\tlearn: 0.2461740\ttotal: 3.36s\tremaining: 6m 9s\n",
      "9:\tlearn: 0.2392000\ttotal: 3.7s\tremaining: 6m 6s\n",
      "10:\tlearn: 0.2340310\ttotal: 4.04s\tremaining: 6m 3s\n",
      "11:\tlearn: 0.2298680\ttotal: 4.39s\tremaining: 6m 1s\n",
      "12:\tlearn: 0.2262336\ttotal: 4.73s\tremaining: 5m 59s\n",
      "13:\tlearn: 0.2232626\ttotal: 5.07s\tremaining: 5m 57s\n",
      "14:\tlearn: 0.2195223\ttotal: 5.43s\tremaining: 5m 56s\n",
      "15:\tlearn: 0.2173005\ttotal: 5.77s\tremaining: 5m 54s\n",
      "16:\tlearn: 0.2152071\ttotal: 6.12s\tremaining: 5m 53s\n",
      "17:\tlearn: 0.2127861\ttotal: 6.48s\tremaining: 5m 53s\n",
      "18:\tlearn: 0.2112233\ttotal: 6.82s\tremaining: 5m 51s\n",
      "19:\tlearn: 0.2088538\ttotal: 7.17s\tremaining: 5m 51s\n",
      "20:\tlearn: 0.2072644\ttotal: 7.51s\tremaining: 5m 50s\n",
      "21:\tlearn: 0.2055109\ttotal: 7.86s\tremaining: 5m 49s\n",
      "22:\tlearn: 0.2035157\ttotal: 8.22s\tremaining: 5m 49s\n",
      "23:\tlearn: 0.2022172\ttotal: 8.57s\tremaining: 5m 48s\n",
      "24:\tlearn: 0.2010179\ttotal: 8.91s\tremaining: 5m 47s\n",
      "25:\tlearn: 0.1999044\ttotal: 9.26s\tremaining: 5m 46s\n",
      "26:\tlearn: 0.1986424\ttotal: 9.61s\tremaining: 5m 46s\n",
      "27:\tlearn: 0.1977552\ttotal: 9.96s\tremaining: 5m 45s\n",
      "28:\tlearn: 0.1965275\ttotal: 10.3s\tremaining: 5m 45s\n",
      "29:\tlearn: 0.1951986\ttotal: 10.7s\tremaining: 5m 44s\n",
      "30:\tlearn: 0.1941937\ttotal: 11s\tremaining: 5m 44s\n",
      "31:\tlearn: 0.1928329\ttotal: 11.4s\tremaining: 5m 43s\n",
      "32:\tlearn: 0.1919708\ttotal: 11.7s\tremaining: 5m 43s\n",
      "33:\tlearn: 0.1911874\ttotal: 12.1s\tremaining: 5m 42s\n",
      "34:\tlearn: 0.1902901\ttotal: 12.4s\tremaining: 5m 42s\n",
      "35:\tlearn: 0.1895132\ttotal: 12.7s\tremaining: 5m 41s\n",
      "36:\tlearn: 0.1880313\ttotal: 13.1s\tremaining: 5m 41s\n",
      "37:\tlearn: 0.1872543\ttotal: 13.5s\tremaining: 5m 40s\n",
      "38:\tlearn: 0.1865952\ttotal: 13.8s\tremaining: 5m 40s\n",
      "39:\tlearn: 0.1852203\ttotal: 14.2s\tremaining: 5m 39s\n",
      "40:\tlearn: 0.1841791\ttotal: 14.5s\tremaining: 5m 39s\n",
      "41:\tlearn: 0.1835908\ttotal: 14.9s\tremaining: 5m 39s\n",
      "42:\tlearn: 0.1826545\ttotal: 15.2s\tremaining: 5m 38s\n",
      "43:\tlearn: 0.1819200\ttotal: 15.6s\tremaining: 5m 38s\n",
      "44:\tlearn: 0.1811950\ttotal: 15.9s\tremaining: 5m 37s\n",
      "45:\tlearn: 0.1806287\ttotal: 16.3s\tremaining: 5m 37s\n",
      "46:\tlearn: 0.1801272\ttotal: 16.6s\tremaining: 5m 36s\n",
      "47:\tlearn: 0.1795957\ttotal: 16.9s\tremaining: 5m 35s\n",
      "48:\tlearn: 0.1790767\ttotal: 17.3s\tremaining: 5m 35s\n",
      "49:\tlearn: 0.1785211\ttotal: 17.6s\tremaining: 5m 34s\n",
      "50:\tlearn: 0.1778155\ttotal: 17.9s\tremaining: 5m 33s\n",
      "51:\tlearn: 0.1771013\ttotal: 18.3s\tremaining: 5m 33s\n",
      "52:\tlearn: 0.1765601\ttotal: 18.7s\tremaining: 5m 33s\n",
      "53:\tlearn: 0.1759295\ttotal: 19s\tremaining: 5m 33s\n",
      "54:\tlearn: 0.1754508\ttotal: 19.4s\tremaining: 5m 32s\n",
      "55:\tlearn: 0.1748753\ttotal: 19.7s\tremaining: 5m 32s\n",
      "56:\tlearn: 0.1742509\ttotal: 20.1s\tremaining: 5m 31s\n",
      "57:\tlearn: 0.1736134\ttotal: 20.4s\tremaining: 5m 31s\n",
      "58:\tlearn: 0.1729768\ttotal: 20.7s\tremaining: 5m 30s\n",
      "59:\tlearn: 0.1724967\ttotal: 21.1s\tremaining: 5m 30s\n",
      "60:\tlearn: 0.1718784\ttotal: 21.4s\tremaining: 5m 29s\n",
      "61:\tlearn: 0.1712489\ttotal: 21.8s\tremaining: 5m 29s\n",
      "62:\tlearn: 0.1706898\ttotal: 22.1s\tremaining: 5m 29s\n",
      "63:\tlearn: 0.1702730\ttotal: 22.5s\tremaining: 5m 28s\n",
      "64:\tlearn: 0.1695127\ttotal: 22.8s\tremaining: 5m 28s\n",
      "65:\tlearn: 0.1690750\ttotal: 23.2s\tremaining: 5m 27s\n",
      "66:\tlearn: 0.1686285\ttotal: 23.5s\tremaining: 5m 27s\n",
      "67:\tlearn: 0.1680190\ttotal: 23.9s\tremaining: 5m 27s\n",
      "68:\tlearn: 0.1676341\ttotal: 24.2s\tremaining: 5m 26s\n",
      "69:\tlearn: 0.1670829\ttotal: 24.6s\tremaining: 5m 26s\n",
      "70:\tlearn: 0.1664166\ttotal: 24.9s\tremaining: 5m 26s\n",
      "71:\tlearn: 0.1659342\ttotal: 25.3s\tremaining: 5m 25s\n",
      "72:\tlearn: 0.1655618\ttotal: 25.6s\tremaining: 5m 25s\n",
      "73:\tlearn: 0.1651512\ttotal: 26s\tremaining: 5m 24s\n",
      "74:\tlearn: 0.1647870\ttotal: 26.3s\tremaining: 5m 24s\n",
      "75:\tlearn: 0.1641737\ttotal: 26.6s\tremaining: 5m 23s\n",
      "76:\tlearn: 0.1636603\ttotal: 27s\tremaining: 5m 23s\n",
      "77:\tlearn: 0.1633116\ttotal: 27.3s\tremaining: 5m 23s\n",
      "78:\tlearn: 0.1629987\ttotal: 27.7s\tremaining: 5m 22s\n",
      "79:\tlearn: 0.1626060\ttotal: 28s\tremaining: 5m 22s\n",
      "80:\tlearn: 0.1622706\ttotal: 28.4s\tremaining: 5m 21s\n",
      "81:\tlearn: 0.1619545\ttotal: 28.7s\tremaining: 5m 21s\n",
      "82:\tlearn: 0.1616265\ttotal: 29.1s\tremaining: 5m 21s\n",
      "83:\tlearn: 0.1612996\ttotal: 29.4s\tremaining: 5m 20s\n",
      "84:\tlearn: 0.1609329\ttotal: 29.8s\tremaining: 5m 20s\n",
      "85:\tlearn: 0.1605984\ttotal: 30.1s\tremaining: 5m 19s\n",
      "86:\tlearn: 0.1603061\ttotal: 30.4s\tremaining: 5m 19s\n",
      "87:\tlearn: 0.1599192\ttotal: 30.8s\tremaining: 5m 19s\n",
      "88:\tlearn: 0.1596402\ttotal: 31.1s\tremaining: 5m 18s\n",
      "89:\tlearn: 0.1593215\ttotal: 31.5s\tremaining: 5m 18s\n",
      "90:\tlearn: 0.1589251\ttotal: 31.8s\tremaining: 5m 17s\n",
      "91:\tlearn: 0.1586172\ttotal: 32.1s\tremaining: 5m 17s\n",
      "92:\tlearn: 0.1582942\ttotal: 32.5s\tremaining: 5m 16s\n",
      "93:\tlearn: 0.1579433\ttotal: 32.8s\tremaining: 5m 16s\n",
      "94:\tlearn: 0.1575789\ttotal: 33.2s\tremaining: 5m 16s\n",
      "95:\tlearn: 0.1572965\ttotal: 33.5s\tremaining: 5m 15s\n",
      "96:\tlearn: 0.1569723\ttotal: 33.9s\tremaining: 5m 15s\n",
      "97:\tlearn: 0.1565978\ttotal: 34.2s\tremaining: 5m 15s\n",
      "98:\tlearn: 0.1563697\ttotal: 34.6s\tremaining: 5m 14s\n",
      "99:\tlearn: 0.1560445\ttotal: 34.9s\tremaining: 5m 14s\n",
      "100:\tlearn: 0.1556719\ttotal: 35.3s\tremaining: 5m 14s\n",
      "101:\tlearn: 0.1553235\ttotal: 35.6s\tremaining: 5m 13s\n",
      "102:\tlearn: 0.1547379\ttotal: 36s\tremaining: 5m 13s\n",
      "103:\tlearn: 0.1542799\ttotal: 36.4s\tremaining: 5m 13s\n",
      "104:\tlearn: 0.1540611\ttotal: 36.7s\tremaining: 5m 12s\n",
      "105:\tlearn: 0.1538041\ttotal: 37.1s\tremaining: 5m 12s\n",
      "106:\tlearn: 0.1535553\ttotal: 37.4s\tremaining: 5m 12s\n",
      "107:\tlearn: 0.1532982\ttotal: 37.7s\tremaining: 5m 11s\n",
      "108:\tlearn: 0.1529263\ttotal: 38.1s\tremaining: 5m 11s\n",
      "109:\tlearn: 0.1526394\ttotal: 38.4s\tremaining: 5m 10s\n",
      "110:\tlearn: 0.1523733\ttotal: 38.8s\tremaining: 5m 10s\n",
      "111:\tlearn: 0.1518901\ttotal: 39.1s\tremaining: 5m 10s\n",
      "112:\tlearn: 0.1516640\ttotal: 39.5s\tremaining: 5m 9s\n",
      "113:\tlearn: 0.1514285\ttotal: 39.8s\tremaining: 5m 9s\n",
      "114:\tlearn: 0.1511768\ttotal: 40.1s\tremaining: 5m 8s\n",
      "115:\tlearn: 0.1508333\ttotal: 40.5s\tremaining: 5m 8s\n",
      "116:\tlearn: 0.1506372\ttotal: 40.8s\tremaining: 5m 8s\n",
      "117:\tlearn: 0.1503716\ttotal: 41.2s\tremaining: 5m 7s\n",
      "118:\tlearn: 0.1501447\ttotal: 41.5s\tremaining: 5m 7s\n",
      "119:\tlearn: 0.1499120\ttotal: 41.9s\tremaining: 5m 6s\n",
      "120:\tlearn: 0.1496613\ttotal: 42.2s\tremaining: 5m 6s\n",
      "121:\tlearn: 0.1493055\ttotal: 42.6s\tremaining: 5m 6s\n",
      "122:\tlearn: 0.1488771\ttotal: 42.9s\tremaining: 5m 5s\n",
      "123:\tlearn: 0.1486940\ttotal: 43.2s\tremaining: 5m 5s\n",
      "124:\tlearn: 0.1484105\ttotal: 43.6s\tremaining: 5m 5s\n",
      "125:\tlearn: 0.1482459\ttotal: 44s\tremaining: 5m 4s\n",
      "126:\tlearn: 0.1479986\ttotal: 44.3s\tremaining: 5m 4s\n",
      "127:\tlearn: 0.1475924\ttotal: 44.6s\tremaining: 5m 4s\n",
      "128:\tlearn: 0.1473553\ttotal: 45s\tremaining: 5m 3s\n",
      "129:\tlearn: 0.1471358\ttotal: 45.3s\tremaining: 5m 3s\n",
      "130:\tlearn: 0.1468228\ttotal: 45.6s\tremaining: 5m 2s\n",
      "131:\tlearn: 0.1466594\ttotal: 46s\tremaining: 5m 2s\n",
      "132:\tlearn: 0.1462085\ttotal: 46.3s\tremaining: 5m 1s\n",
      "133:\tlearn: 0.1459710\ttotal: 46.7s\tremaining: 5m 1s\n",
      "134:\tlearn: 0.1457947\ttotal: 47s\tremaining: 5m 1s\n",
      "135:\tlearn: 0.1455768\ttotal: 47.4s\tremaining: 5m\n",
      "136:\tlearn: 0.1452986\ttotal: 47.7s\tremaining: 5m\n",
      "137:\tlearn: 0.1450728\ttotal: 48s\tremaining: 5m\n",
      "138:\tlearn: 0.1448336\ttotal: 48.4s\tremaining: 4m 59s\n",
      "139:\tlearn: 0.1445731\ttotal: 48.7s\tremaining: 4m 59s\n",
      "140:\tlearn: 0.1443698\ttotal: 49.1s\tremaining: 4m 59s\n",
      "141:\tlearn: 0.1441355\ttotal: 49.4s\tremaining: 4m 58s\n",
      "142:\tlearn: 0.1440078\ttotal: 49.8s\tremaining: 4m 58s\n",
      "143:\tlearn: 0.1438677\ttotal: 50.1s\tremaining: 4m 58s\n",
      "144:\tlearn: 0.1436734\ttotal: 50.5s\tremaining: 4m 57s\n",
      "145:\tlearn: 0.1435364\ttotal: 50.9s\tremaining: 4m 57s\n",
      "146:\tlearn: 0.1433207\ttotal: 51.2s\tremaining: 4m 57s\n",
      "147:\tlearn: 0.1431002\ttotal: 51.6s\tremaining: 4m 56s\n",
      "148:\tlearn: 0.1428609\ttotal: 51.9s\tremaining: 4m 56s\n",
      "149:\tlearn: 0.1427460\ttotal: 52.2s\tremaining: 4m 56s\n",
      "150:\tlearn: 0.1425623\ttotal: 52.6s\tremaining: 4m 55s\n",
      "151:\tlearn: 0.1423643\ttotal: 52.9s\tremaining: 4m 55s\n",
      "152:\tlearn: 0.1421087\ttotal: 53.3s\tremaining: 4m 54s\n",
      "153:\tlearn: 0.1419849\ttotal: 53.6s\tremaining: 4m 54s\n",
      "154:\tlearn: 0.1417311\ttotal: 53.9s\tremaining: 4m 54s\n",
      "155:\tlearn: 0.1415853\ttotal: 54.3s\tremaining: 4m 53s\n",
      "156:\tlearn: 0.1413447\ttotal: 54.6s\tremaining: 4m 53s\n",
      "157:\tlearn: 0.1412198\ttotal: 55s\tremaining: 4m 52s\n",
      "158:\tlearn: 0.1410803\ttotal: 55.3s\tremaining: 4m 52s\n",
      "159:\tlearn: 0.1408695\ttotal: 55.6s\tremaining: 4m 51s\n",
      "160:\tlearn: 0.1405972\ttotal: 56s\tremaining: 4m 51s\n",
      "161:\tlearn: 0.1404455\ttotal: 56.3s\tremaining: 4m 51s\n",
      "162:\tlearn: 0.1403167\ttotal: 56.6s\tremaining: 4m 50s\n",
      "163:\tlearn: 0.1400969\ttotal: 56.9s\tremaining: 4m 50s\n",
      "164:\tlearn: 0.1398476\ttotal: 57.3s\tremaining: 4m 49s\n",
      "165:\tlearn: 0.1396721\ttotal: 57.6s\tremaining: 4m 49s\n",
      "166:\tlearn: 0.1395051\ttotal: 57.9s\tremaining: 4m 49s\n",
      "167:\tlearn: 0.1393494\ttotal: 58.3s\tremaining: 4m 48s\n",
      "168:\tlearn: 0.1391518\ttotal: 58.6s\tremaining: 4m 48s\n",
      "169:\tlearn: 0.1389568\ttotal: 58.9s\tremaining: 4m 47s\n",
      "170:\tlearn: 0.1387924\ttotal: 59.3s\tremaining: 4m 47s\n",
      "171:\tlearn: 0.1385816\ttotal: 59.6s\tremaining: 4m 46s\n",
      "172:\tlearn: 0.1384576\ttotal: 60s\tremaining: 4m 46s\n",
      "173:\tlearn: 0.1382073\ttotal: 1m\tremaining: 4m 46s\n",
      "174:\tlearn: 0.1381115\ttotal: 1m\tremaining: 4m 45s\n",
      "175:\tlearn: 0.1379450\ttotal: 1m\tremaining: 4m 45s\n",
      "176:\tlearn: 0.1378461\ttotal: 1m 1s\tremaining: 4m 44s\n",
      "177:\tlearn: 0.1376241\ttotal: 1m 1s\tremaining: 4m 44s\n",
      "178:\tlearn: 0.1374320\ttotal: 1m 1s\tremaining: 4m 44s\n",
      "179:\tlearn: 0.1373307\ttotal: 1m 2s\tremaining: 4m 43s\n",
      "180:\tlearn: 0.1370753\ttotal: 1m 2s\tremaining: 4m 43s\n",
      "181:\tlearn: 0.1369851\ttotal: 1m 2s\tremaining: 4m 42s\n",
      "182:\tlearn: 0.1368985\ttotal: 1m 3s\tremaining: 4m 42s\n",
      "183:\tlearn: 0.1367134\ttotal: 1m 3s\tremaining: 4m 42s\n",
      "184:\tlearn: 0.1365359\ttotal: 1m 3s\tremaining: 4m 41s\n",
      "185:\tlearn: 0.1364557\ttotal: 1m 4s\tremaining: 4m 41s\n",
      "186:\tlearn: 0.1362022\ttotal: 1m 4s\tremaining: 4m 41s\n",
      "187:\tlearn: 0.1360787\ttotal: 1m 4s\tremaining: 4m 40s\n",
      "188:\tlearn: 0.1358704\ttotal: 1m 5s\tremaining: 4m 40s\n",
      "189:\tlearn: 0.1357134\ttotal: 1m 5s\tremaining: 4m 39s\n",
      "190:\tlearn: 0.1355753\ttotal: 1m 5s\tremaining: 4m 39s\n",
      "191:\tlearn: 0.1353853\ttotal: 1m 6s\tremaining: 4m 39s\n",
      "192:\tlearn: 0.1352375\ttotal: 1m 6s\tremaining: 4m 38s\n",
      "193:\tlearn: 0.1351044\ttotal: 1m 7s\tremaining: 4m 38s\n",
      "194:\tlearn: 0.1349322\ttotal: 1m 7s\tremaining: 4m 38s\n",
      "195:\tlearn: 0.1348072\ttotal: 1m 7s\tremaining: 4m 37s\n",
      "196:\tlearn: 0.1345838\ttotal: 1m 8s\tremaining: 4m 37s\n",
      "197:\tlearn: 0.1343469\ttotal: 1m 8s\tremaining: 4m 36s\n",
      "198:\tlearn: 0.1342615\ttotal: 1m 8s\tremaining: 4m 36s\n",
      "199:\tlearn: 0.1341638\ttotal: 1m 9s\tremaining: 4m 36s\n",
      "200:\tlearn: 0.1340348\ttotal: 1m 9s\tremaining: 4m 35s\n",
      "201:\tlearn: 0.1338730\ttotal: 1m 9s\tremaining: 4m 35s\n",
      "202:\tlearn: 0.1337119\ttotal: 1m 10s\tremaining: 4m 34s\n",
      "203:\tlearn: 0.1335534\ttotal: 1m 10s\tremaining: 4m 34s\n",
      "204:\tlearn: 0.1334646\ttotal: 1m 10s\tremaining: 4m 34s\n",
      "205:\tlearn: 0.1332856\ttotal: 1m 11s\tremaining: 4m 33s\n",
      "206:\tlearn: 0.1331350\ttotal: 1m 11s\tremaining: 4m 33s\n",
      "207:\tlearn: 0.1330156\ttotal: 1m 11s\tremaining: 4m 33s\n",
      "208:\tlearn: 0.1329239\ttotal: 1m 12s\tremaining: 4m 32s\n",
      "209:\tlearn: 0.1328483\ttotal: 1m 12s\tremaining: 4m 32s\n",
      "210:\tlearn: 0.1326974\ttotal: 1m 12s\tremaining: 4m 31s\n",
      "211:\tlearn: 0.1324491\ttotal: 1m 13s\tremaining: 4m 31s\n",
      "212:\tlearn: 0.1323385\ttotal: 1m 13s\tremaining: 4m 31s\n",
      "213:\tlearn: 0.1321736\ttotal: 1m 13s\tremaining: 4m 30s\n",
      "214:\tlearn: 0.1320915\ttotal: 1m 14s\tremaining: 4m 30s\n",
      "215:\tlearn: 0.1320199\ttotal: 1m 14s\tremaining: 4m 29s\n",
      "216:\tlearn: 0.1319420\ttotal: 1m 14s\tremaining: 4m 29s\n",
      "217:\tlearn: 0.1318054\ttotal: 1m 15s\tremaining: 4m 29s\n",
      "218:\tlearn: 0.1316359\ttotal: 1m 15s\tremaining: 4m 28s\n",
      "219:\tlearn: 0.1314741\ttotal: 1m 15s\tremaining: 4m 28s\n",
      "220:\tlearn: 0.1314054\ttotal: 1m 16s\tremaining: 4m 27s\n",
      "221:\tlearn: 0.1311895\ttotal: 1m 16s\tremaining: 4m 27s\n",
      "222:\tlearn: 0.1311059\ttotal: 1m 16s\tremaining: 4m 27s\n",
      "223:\tlearn: 0.1310359\ttotal: 1m 17s\tremaining: 4m 26s\n",
      "224:\tlearn: 0.1309729\ttotal: 1m 17s\tremaining: 4m 26s\n",
      "225:\tlearn: 0.1308428\ttotal: 1m 17s\tremaining: 4m 26s\n",
      "226:\tlearn: 0.1307051\ttotal: 1m 18s\tremaining: 4m 25s\n",
      "227:\tlearn: 0.1305305\ttotal: 1m 18s\tremaining: 4m 25s\n",
      "228:\tlearn: 0.1304598\ttotal: 1m 18s\tremaining: 4m 24s\n",
      "229:\tlearn: 0.1302195\ttotal: 1m 19s\tremaining: 4m 24s\n",
      "230:\tlearn: 0.1300541\ttotal: 1m 19s\tremaining: 4m 24s\n",
      "231:\tlearn: 0.1299488\ttotal: 1m 19s\tremaining: 4m 23s\n",
      "232:\tlearn: 0.1298743\ttotal: 1m 20s\tremaining: 4m 23s\n",
      "233:\tlearn: 0.1297827\ttotal: 1m 20s\tremaining: 4m 23s\n",
      "234:\tlearn: 0.1297175\ttotal: 1m 20s\tremaining: 4m 22s\n",
      "235:\tlearn: 0.1294985\ttotal: 1m 21s\tremaining: 4m 22s\n",
      "236:\tlearn: 0.1293218\ttotal: 1m 21s\tremaining: 4m 21s\n",
      "237:\tlearn: 0.1291470\ttotal: 1m 21s\tremaining: 4m 21s\n",
      "238:\tlearn: 0.1290358\ttotal: 1m 22s\tremaining: 4m 21s\n",
      "239:\tlearn: 0.1289556\ttotal: 1m 22s\tremaining: 4m 20s\n",
      "240:\tlearn: 0.1287971\ttotal: 1m 22s\tremaining: 4m 20s\n",
      "241:\tlearn: 0.1287157\ttotal: 1m 23s\tremaining: 4m 20s\n",
      "242:\tlearn: 0.1285760\ttotal: 1m 23s\tremaining: 4m 19s\n",
      "243:\tlearn: 0.1284557\ttotal: 1m 23s\tremaining: 4m 19s\n",
      "244:\tlearn: 0.1283532\ttotal: 1m 24s\tremaining: 4m 19s\n",
      "245:\tlearn: 0.1281908\ttotal: 1m 24s\tremaining: 4m 18s\n",
      "246:\tlearn: 0.1280499\ttotal: 1m 24s\tremaining: 4m 18s\n",
      "247:\tlearn: 0.1279588\ttotal: 1m 25s\tremaining: 4m 18s\n",
      "248:\tlearn: 0.1277823\ttotal: 1m 25s\tremaining: 4m 17s\n",
      "249:\tlearn: 0.1277109\ttotal: 1m 25s\tremaining: 4m 17s\n",
      "250:\tlearn: 0.1275739\ttotal: 1m 26s\tremaining: 4m 17s\n",
      "251:\tlearn: 0.1275163\ttotal: 1m 26s\tremaining: 4m 16s\n",
      "252:\tlearn: 0.1274542\ttotal: 1m 26s\tremaining: 4m 16s\n",
      "253:\tlearn: 0.1272959\ttotal: 1m 27s\tremaining: 4m 15s\n",
      "254:\tlearn: 0.1271209\ttotal: 1m 27s\tremaining: 4m 15s\n",
      "255:\tlearn: 0.1269705\ttotal: 1m 27s\tremaining: 4m 15s\n",
      "256:\tlearn: 0.1269093\ttotal: 1m 28s\tremaining: 4m 14s\n",
      "257:\tlearn: 0.1266892\ttotal: 1m 28s\tremaining: 4m 14s\n",
      "258:\tlearn: 0.1265753\ttotal: 1m 28s\tremaining: 4m 14s\n",
      "259:\tlearn: 0.1264549\ttotal: 1m 29s\tremaining: 4m 13s\n",
      "260:\tlearn: 0.1263291\ttotal: 1m 29s\tremaining: 4m 13s\n",
      "261:\tlearn: 0.1262223\ttotal: 1m 29s\tremaining: 4m 13s\n",
      "262:\tlearn: 0.1261128\ttotal: 1m 30s\tremaining: 4m 12s\n",
      "263:\tlearn: 0.1259481\ttotal: 1m 30s\tremaining: 4m 12s\n",
      "264:\tlearn: 0.1258680\ttotal: 1m 30s\tremaining: 4m 12s\n",
      "265:\tlearn: 0.1257931\ttotal: 1m 31s\tremaining: 4m 11s\n",
      "266:\tlearn: 0.1257363\ttotal: 1m 31s\tremaining: 4m 11s\n",
      "267:\tlearn: 0.1256095\ttotal: 1m 31s\tremaining: 4m 10s\n",
      "268:\tlearn: 0.1254934\ttotal: 1m 32s\tremaining: 4m 10s\n",
      "269:\tlearn: 0.1253070\ttotal: 1m 32s\tremaining: 4m 10s\n",
      "270:\tlearn: 0.1251840\ttotal: 1m 32s\tremaining: 4m 9s\n",
      "271:\tlearn: 0.1250491\ttotal: 1m 33s\tremaining: 4m 9s\n",
      "272:\tlearn: 0.1249974\ttotal: 1m 33s\tremaining: 4m 9s\n",
      "273:\tlearn: 0.1249460\ttotal: 1m 33s\tremaining: 4m 8s\n",
      "274:\tlearn: 0.1247936\ttotal: 1m 34s\tremaining: 4m 8s\n",
      "275:\tlearn: 0.1246221\ttotal: 1m 34s\tremaining: 4m 8s\n",
      "276:\tlearn: 0.1245016\ttotal: 1m 34s\tremaining: 4m 7s\n",
      "277:\tlearn: 0.1244038\ttotal: 1m 35s\tremaining: 4m 7s\n",
      "278:\tlearn: 0.1243480\ttotal: 1m 35s\tremaining: 4m 7s\n",
      "279:\tlearn: 0.1242311\ttotal: 1m 36s\tremaining: 4m 6s\n",
      "280:\tlearn: 0.1240936\ttotal: 1m 36s\tremaining: 4m 6s\n",
      "281:\tlearn: 0.1240397\ttotal: 1m 36s\tremaining: 4m 6s\n",
      "282:\tlearn: 0.1238715\ttotal: 1m 37s\tremaining: 4m 5s\n",
      "283:\tlearn: 0.1237869\ttotal: 1m 37s\tremaining: 4m 5s\n",
      "284:\tlearn: 0.1237334\ttotal: 1m 37s\tremaining: 4m 5s\n",
      "285:\tlearn: 0.1236392\ttotal: 1m 38s\tremaining: 4m 4s\n",
      "286:\tlearn: 0.1235639\ttotal: 1m 38s\tremaining: 4m 4s\n",
      "287:\tlearn: 0.1234664\ttotal: 1m 38s\tremaining: 4m 4s\n",
      "288:\tlearn: 0.1234126\ttotal: 1m 39s\tremaining: 4m 3s\n",
      "289:\tlearn: 0.1232982\ttotal: 1m 39s\tremaining: 4m 3s\n",
      "290:\tlearn: 0.1231565\ttotal: 1m 39s\tremaining: 4m 3s\n",
      "291:\tlearn: 0.1230666\ttotal: 1m 40s\tremaining: 4m 2s\n",
      "292:\tlearn: 0.1230153\ttotal: 1m 40s\tremaining: 4m 2s\n",
      "293:\tlearn: 0.1229616\ttotal: 1m 40s\tremaining: 4m 1s\n",
      "294:\tlearn: 0.1228994\ttotal: 1m 41s\tremaining: 4m 1s\n",
      "295:\tlearn: 0.1228150\ttotal: 1m 41s\tremaining: 4m 1s\n",
      "296:\tlearn: 0.1227607\ttotal: 1m 41s\tremaining: 4m\n",
      "297:\tlearn: 0.1227095\ttotal: 1m 42s\tremaining: 4m\n",
      "298:\tlearn: 0.1225336\ttotal: 1m 42s\tremaining: 4m\n",
      "299:\tlearn: 0.1224841\ttotal: 1m 42s\tremaining: 3m 59s\n",
      "300:\tlearn: 0.1224356\ttotal: 1m 43s\tremaining: 3m 59s\n",
      "301:\tlearn: 0.1223823\ttotal: 1m 43s\tremaining: 3m 59s\n",
      "302:\tlearn: 0.1221857\ttotal: 1m 43s\tremaining: 3m 58s\n",
      "303:\tlearn: 0.1220752\ttotal: 1m 44s\tremaining: 3m 58s\n",
      "304:\tlearn: 0.1220109\ttotal: 1m 44s\tremaining: 3m 57s\n",
      "305:\tlearn: 0.1219628\ttotal: 1m 44s\tremaining: 3m 57s\n",
      "306:\tlearn: 0.1219086\ttotal: 1m 45s\tremaining: 3m 57s\n",
      "307:\tlearn: 0.1218094\ttotal: 1m 45s\tremaining: 3m 56s\n",
      "308:\tlearn: 0.1216478\ttotal: 1m 45s\tremaining: 3m 56s\n",
      "309:\tlearn: 0.1216009\ttotal: 1m 46s\tremaining: 3m 56s\n",
      "310:\tlearn: 0.1215561\ttotal: 1m 46s\tremaining: 3m 55s\n",
      "311:\tlearn: 0.1215018\ttotal: 1m 46s\tremaining: 3m 55s\n",
      "312:\tlearn: 0.1214494\ttotal: 1m 47s\tremaining: 3m 55s\n",
      "313:\tlearn: 0.1214043\ttotal: 1m 47s\tremaining: 3m 54s\n",
      "314:\tlearn: 0.1213602\ttotal: 1m 47s\tremaining: 3m 54s\n",
      "315:\tlearn: 0.1212602\ttotal: 1m 48s\tremaining: 3m 54s\n",
      "316:\tlearn: 0.1212198\ttotal: 1m 48s\tremaining: 3m 53s\n",
      "317:\tlearn: 0.1211751\ttotal: 1m 48s\tremaining: 3m 53s\n",
      "318:\tlearn: 0.1210959\ttotal: 1m 49s\tremaining: 3m 53s\n",
      "319:\tlearn: 0.1210507\ttotal: 1m 49s\tremaining: 3m 52s\n",
      "320:\tlearn: 0.1210090\ttotal: 1m 49s\tremaining: 3m 52s\n",
      "321:\tlearn: 0.1209556\ttotal: 1m 50s\tremaining: 3m 52s\n",
      "322:\tlearn: 0.1208351\ttotal: 1m 50s\tremaining: 3m 51s\n",
      "323:\tlearn: 0.1207910\ttotal: 1m 50s\tremaining: 3m 51s\n",
      "324:\tlearn: 0.1207024\ttotal: 1m 51s\tremaining: 3m 51s\n",
      "325:\tlearn: 0.1205541\ttotal: 1m 51s\tremaining: 3m 50s\n",
      "326:\tlearn: 0.1204612\ttotal: 1m 52s\tremaining: 3m 50s\n",
      "327:\tlearn: 0.1203700\ttotal: 1m 52s\tremaining: 3m 50s\n",
      "328:\tlearn: 0.1202109\ttotal: 1m 52s\tremaining: 3m 49s\n",
      "329:\tlearn: 0.1201675\ttotal: 1m 53s\tremaining: 3m 49s\n",
      "330:\tlearn: 0.1201130\ttotal: 1m 53s\tremaining: 3m 49s\n",
      "331:\tlearn: 0.1199610\ttotal: 1m 53s\tremaining: 3m 49s\n",
      "332:\tlearn: 0.1199212\ttotal: 1m 54s\tremaining: 3m 49s\n",
      "333:\tlearn: 0.1198831\ttotal: 1m 54s\tremaining: 3m 48s\n",
      "334:\tlearn: 0.1197688\ttotal: 1m 55s\tremaining: 3m 48s\n",
      "335:\tlearn: 0.1195941\ttotal: 1m 55s\tremaining: 3m 48s\n",
      "336:\tlearn: 0.1194656\ttotal: 1m 55s\tremaining: 3m 47s\n",
      "337:\tlearn: 0.1194144\ttotal: 1m 56s\tremaining: 3m 47s\n",
      "338:\tlearn: 0.1193709\ttotal: 1m 56s\tremaining: 3m 47s\n",
      "339:\tlearn: 0.1192573\ttotal: 1m 56s\tremaining: 3m 46s\n",
      "340:\tlearn: 0.1192100\ttotal: 1m 57s\tremaining: 3m 46s\n",
      "341:\tlearn: 0.1190909\ttotal: 1m 57s\tremaining: 3m 46s\n",
      "342:\tlearn: 0.1190121\ttotal: 1m 57s\tremaining: 3m 45s\n",
      "343:\tlearn: 0.1188771\ttotal: 1m 58s\tremaining: 3m 45s\n",
      "344:\tlearn: 0.1187434\ttotal: 1m 58s\tremaining: 3m 45s\n",
      "345:\tlearn: 0.1187024\ttotal: 1m 59s\tremaining: 3m 44s\n",
      "346:\tlearn: 0.1186614\ttotal: 1m 59s\tremaining: 3m 44s\n",
      "347:\tlearn: 0.1186199\ttotal: 1m 59s\tremaining: 3m 44s\n",
      "348:\tlearn: 0.1185144\ttotal: 2m\tremaining: 3m 43s\n",
      "349:\tlearn: 0.1184777\ttotal: 2m\tremaining: 3m 43s\n",
      "350:\tlearn: 0.1183965\ttotal: 2m\tremaining: 3m 43s\n",
      "351:\tlearn: 0.1183546\ttotal: 2m 1s\tremaining: 3m 43s\n",
      "352:\tlearn: 0.1183153\ttotal: 2m 1s\tremaining: 3m 42s\n",
      "353:\tlearn: 0.1182760\ttotal: 2m 1s\tremaining: 3m 42s\n",
      "354:\tlearn: 0.1182013\ttotal: 2m 2s\tremaining: 3m 42s\n",
      "355:\tlearn: 0.1181033\ttotal: 2m 2s\tremaining: 3m 41s\n",
      "356:\tlearn: 0.1180655\ttotal: 2m 2s\tremaining: 3m 41s\n",
      "357:\tlearn: 0.1178808\ttotal: 2m 3s\tremaining: 3m 41s\n",
      "358:\tlearn: 0.1178410\ttotal: 2m 3s\tremaining: 3m 40s\n",
      "359:\tlearn: 0.1177966\ttotal: 2m 3s\tremaining: 3m 40s\n",
      "360:\tlearn: 0.1177122\ttotal: 2m 4s\tremaining: 3m 40s\n",
      "361:\tlearn: 0.1176753\ttotal: 2m 4s\tremaining: 3m 39s\n",
      "362:\tlearn: 0.1175755\ttotal: 2m 5s\tremaining: 3m 39s\n",
      "363:\tlearn: 0.1174631\ttotal: 2m 5s\tremaining: 3m 39s\n",
      "364:\tlearn: 0.1174256\ttotal: 2m 5s\tremaining: 3m 38s\n",
      "365:\tlearn: 0.1173229\ttotal: 2m 6s\tremaining: 3m 38s\n",
      "366:\tlearn: 0.1172874\ttotal: 2m 6s\tremaining: 3m 37s\n",
      "367:\tlearn: 0.1172498\ttotal: 2m 6s\tremaining: 3m 37s\n",
      "368:\tlearn: 0.1172005\ttotal: 2m 7s\tremaining: 3m 37s\n",
      "369:\tlearn: 0.1171337\ttotal: 2m 7s\tremaining: 3m 37s\n",
      "370:\tlearn: 0.1170371\ttotal: 2m 7s\tremaining: 3m 36s\n",
      "371:\tlearn: 0.1170019\ttotal: 2m 8s\tremaining: 3m 36s\n",
      "372:\tlearn: 0.1168816\ttotal: 2m 8s\tremaining: 3m 36s\n",
      "373:\tlearn: 0.1168345\ttotal: 2m 8s\tremaining: 3m 35s\n",
      "374:\tlearn: 0.1167939\ttotal: 2m 9s\tremaining: 3m 35s\n",
      "375:\tlearn: 0.1166783\ttotal: 2m 9s\tremaining: 3m 35s\n",
      "376:\tlearn: 0.1166399\ttotal: 2m 9s\tremaining: 3m 34s\n",
      "377:\tlearn: 0.1165286\ttotal: 2m 10s\tremaining: 3m 34s\n",
      "378:\tlearn: 0.1164524\ttotal: 2m 10s\tremaining: 3m 34s\n",
      "379:\tlearn: 0.1163937\ttotal: 2m 11s\tremaining: 3m 33s\n",
      "380:\tlearn: 0.1163486\ttotal: 2m 11s\tremaining: 3m 33s\n",
      "381:\tlearn: 0.1162854\ttotal: 2m 11s\tremaining: 3m 33s\n",
      "382:\tlearn: 0.1162424\ttotal: 2m 12s\tremaining: 3m 32s\n",
      "383:\tlearn: 0.1161747\ttotal: 2m 12s\tremaining: 3m 32s\n",
      "384:\tlearn: 0.1160716\ttotal: 2m 12s\tremaining: 3m 32s\n",
      "385:\tlearn: 0.1160363\ttotal: 2m 13s\tremaining: 3m 31s\n",
      "386:\tlearn: 0.1160009\ttotal: 2m 13s\tremaining: 3m 31s\n",
      "387:\tlearn: 0.1158951\ttotal: 2m 13s\tremaining: 3m 31s\n",
      "388:\tlearn: 0.1156947\ttotal: 2m 14s\tremaining: 3m 30s\n",
      "389:\tlearn: 0.1156016\ttotal: 2m 14s\tremaining: 3m 30s\n",
      "390:\tlearn: 0.1155126\ttotal: 2m 14s\tremaining: 3m 30s\n",
      "391:\tlearn: 0.1154665\ttotal: 2m 15s\tremaining: 3m 29s\n",
      "392:\tlearn: 0.1154315\ttotal: 2m 15s\tremaining: 3m 29s\n",
      "393:\tlearn: 0.1153132\ttotal: 2m 15s\tremaining: 3m 29s\n",
      "394:\tlearn: 0.1152670\ttotal: 2m 16s\tremaining: 3m 28s\n",
      "395:\tlearn: 0.1152295\ttotal: 2m 16s\tremaining: 3m 28s\n",
      "396:\tlearn: 0.1151949\ttotal: 2m 16s\tremaining: 3m 28s\n",
      "397:\tlearn: 0.1151625\ttotal: 2m 17s\tremaining: 3m 27s\n",
      "398:\tlearn: 0.1150766\ttotal: 2m 17s\tremaining: 3m 27s\n",
      "399:\tlearn: 0.1149874\ttotal: 2m 17s\tremaining: 3m 26s\n",
      "400:\tlearn: 0.1148821\ttotal: 2m 18s\tremaining: 3m 26s\n",
      "401:\tlearn: 0.1148473\ttotal: 2m 18s\tremaining: 3m 26s\n",
      "402:\tlearn: 0.1148140\ttotal: 2m 19s\tremaining: 3m 25s\n",
      "403:\tlearn: 0.1147683\ttotal: 2m 19s\tremaining: 3m 25s\n",
      "404:\tlearn: 0.1146826\ttotal: 2m 19s\tremaining: 3m 25s\n",
      "405:\tlearn: 0.1146469\ttotal: 2m 20s\tremaining: 3m 24s\n",
      "406:\tlearn: 0.1145812\ttotal: 2m 20s\tremaining: 3m 24s\n",
      "407:\tlearn: 0.1144829\ttotal: 2m 20s\tremaining: 3m 24s\n",
      "408:\tlearn: 0.1143731\ttotal: 2m 21s\tremaining: 3m 23s\n",
      "409:\tlearn: 0.1142619\ttotal: 2m 21s\tremaining: 3m 23s\n",
      "410:\tlearn: 0.1142293\ttotal: 2m 21s\tremaining: 3m 23s\n",
      "411:\tlearn: 0.1141839\ttotal: 2m 22s\tremaining: 3m 22s\n",
      "412:\tlearn: 0.1141508\ttotal: 2m 22s\tremaining: 3m 22s\n",
      "413:\tlearn: 0.1140631\ttotal: 2m 22s\tremaining: 3m 22s\n",
      "414:\tlearn: 0.1139755\ttotal: 2m 23s\tremaining: 3m 21s\n",
      "415:\tlearn: 0.1138955\ttotal: 2m 23s\tremaining: 3m 21s\n",
      "416:\tlearn: 0.1138605\ttotal: 2m 23s\tremaining: 3m 21s\n",
      "417:\tlearn: 0.1137574\ttotal: 2m 24s\tremaining: 3m 20s\n",
      "418:\tlearn: 0.1136788\ttotal: 2m 24s\tremaining: 3m 20s\n",
      "419:\tlearn: 0.1136242\ttotal: 2m 24s\tremaining: 3m 20s\n",
      "420:\tlearn: 0.1135404\ttotal: 2m 25s\tremaining: 3m 19s\n",
      "421:\tlearn: 0.1135093\ttotal: 2m 25s\tremaining: 3m 19s\n",
      "422:\tlearn: 0.1134186\ttotal: 2m 25s\tremaining: 3m 19s\n",
      "423:\tlearn: 0.1133057\ttotal: 2m 26s\tremaining: 3m 18s\n",
      "424:\tlearn: 0.1132736\ttotal: 2m 26s\tremaining: 3m 18s\n",
      "425:\tlearn: 0.1132251\ttotal: 2m 26s\tremaining: 3m 18s\n",
      "426:\tlearn: 0.1131417\ttotal: 2m 27s\tremaining: 3m 17s\n",
      "427:\tlearn: 0.1130495\ttotal: 2m 27s\tremaining: 3m 17s\n",
      "428:\tlearn: 0.1129776\ttotal: 2m 28s\tremaining: 3m 17s\n",
      "429:\tlearn: 0.1128848\ttotal: 2m 28s\tremaining: 3m 16s\n",
      "430:\tlearn: 0.1128509\ttotal: 2m 28s\tremaining: 3m 16s\n",
      "431:\tlearn: 0.1128076\ttotal: 2m 29s\tremaining: 3m 15s\n",
      "432:\tlearn: 0.1127617\ttotal: 2m 29s\tremaining: 3m 15s\n",
      "433:\tlearn: 0.1126891\ttotal: 2m 29s\tremaining: 3m 15s\n",
      "434:\tlearn: 0.1126544\ttotal: 2m 30s\tremaining: 3m 14s\n",
      "435:\tlearn: 0.1126224\ttotal: 2m 30s\tremaining: 3m 14s\n",
      "436:\tlearn: 0.1125903\ttotal: 2m 30s\tremaining: 3m 14s\n",
      "437:\tlearn: 0.1124841\ttotal: 2m 31s\tremaining: 3m 13s\n",
      "438:\tlearn: 0.1124074\ttotal: 2m 31s\tremaining: 3m 13s\n",
      "439:\tlearn: 0.1123703\ttotal: 2m 31s\tremaining: 3m 13s\n",
      "440:\tlearn: 0.1123136\ttotal: 2m 32s\tremaining: 3m 12s\n",
      "441:\tlearn: 0.1122277\ttotal: 2m 32s\tremaining: 3m 12s\n",
      "442:\tlearn: 0.1121964\ttotal: 2m 32s\tremaining: 3m 12s\n",
      "443:\tlearn: 0.1121656\ttotal: 2m 33s\tremaining: 3m 11s\n",
      "444:\tlearn: 0.1120873\ttotal: 2m 33s\tremaining: 3m 11s\n",
      "445:\tlearn: 0.1119653\ttotal: 2m 33s\tremaining: 3m 11s\n",
      "446:\tlearn: 0.1119354\ttotal: 2m 34s\tremaining: 3m 10s\n",
      "447:\tlearn: 0.1119048\ttotal: 2m 34s\tremaining: 3m 10s\n",
      "448:\tlearn: 0.1118729\ttotal: 2m 34s\tremaining: 3m 10s\n",
      "449:\tlearn: 0.1118249\ttotal: 2m 35s\tremaining: 3m 9s\n",
      "450:\tlearn: 0.1117119\ttotal: 2m 35s\tremaining: 3m 9s\n",
      "451:\tlearn: 0.1116668\ttotal: 2m 35s\tremaining: 3m 9s\n",
      "452:\tlearn: 0.1115488\ttotal: 2m 36s\tremaining: 3m 8s\n",
      "453:\tlearn: 0.1115090\ttotal: 2m 36s\tremaining: 3m 8s\n",
      "454:\tlearn: 0.1114671\ttotal: 2m 36s\tremaining: 3m 7s\n",
      "455:\tlearn: 0.1113672\ttotal: 2m 37s\tremaining: 3m 7s\n",
      "456:\tlearn: 0.1112819\ttotal: 2m 37s\tremaining: 3m 7s\n",
      "457:\tlearn: 0.1111957\ttotal: 2m 37s\tremaining: 3m 6s\n",
      "458:\tlearn: 0.1111681\ttotal: 2m 38s\tremaining: 3m 6s\n",
      "459:\tlearn: 0.1111396\ttotal: 2m 38s\tremaining: 3m 6s\n",
      "460:\tlearn: 0.1110331\ttotal: 2m 39s\tremaining: 3m 5s\n",
      "461:\tlearn: 0.1109843\ttotal: 2m 39s\tremaining: 3m 5s\n",
      "462:\tlearn: 0.1109535\ttotal: 2m 39s\tremaining: 3m 5s\n",
      "463:\tlearn: 0.1109167\ttotal: 2m 40s\tremaining: 3m 5s\n",
      "464:\tlearn: 0.1107933\ttotal: 2m 40s\tremaining: 3m 4s\n",
      "465:\tlearn: 0.1107638\ttotal: 2m 40s\tremaining: 3m 4s\n",
      "466:\tlearn: 0.1107145\ttotal: 2m 41s\tremaining: 3m 3s\n",
      "467:\tlearn: 0.1106357\ttotal: 2m 41s\tremaining: 3m 3s\n",
      "468:\tlearn: 0.1105996\ttotal: 2m 41s\tremaining: 3m 3s\n",
      "469:\tlearn: 0.1105492\ttotal: 2m 42s\tremaining: 3m 2s\n",
      "470:\tlearn: 0.1104980\ttotal: 2m 42s\tremaining: 3m 2s\n",
      "471:\tlearn: 0.1104211\ttotal: 2m 42s\tremaining: 3m 2s\n",
      "472:\tlearn: 0.1103295\ttotal: 2m 43s\tremaining: 3m 1s\n",
      "473:\tlearn: 0.1102638\ttotal: 2m 43s\tremaining: 3m 1s\n",
      "474:\tlearn: 0.1101860\ttotal: 2m 44s\tremaining: 3m 1s\n",
      "475:\tlearn: 0.1101047\ttotal: 2m 44s\tremaining: 3m\n",
      "476:\tlearn: 0.1100180\ttotal: 2m 44s\tremaining: 3m\n",
      "477:\tlearn: 0.1099879\ttotal: 2m 45s\tremaining: 3m\n",
      "478:\tlearn: 0.1099590\ttotal: 2m 45s\tremaining: 2m 59s\n",
      "479:\tlearn: 0.1098932\ttotal: 2m 45s\tremaining: 2m 59s\n",
      "480:\tlearn: 0.1098644\ttotal: 2m 46s\tremaining: 2m 59s\n",
      "481:\tlearn: 0.1098264\ttotal: 2m 46s\tremaining: 2m 58s\n",
      "482:\tlearn: 0.1097074\ttotal: 2m 46s\tremaining: 2m 58s\n",
      "483:\tlearn: 0.1096367\ttotal: 2m 47s\tremaining: 2m 58s\n",
      "484:\tlearn: 0.1096085\ttotal: 2m 47s\tremaining: 2m 57s\n",
      "485:\tlearn: 0.1095736\ttotal: 2m 47s\tremaining: 2m 57s\n",
      "486:\tlearn: 0.1094915\ttotal: 2m 48s\tremaining: 2m 57s\n",
      "487:\tlearn: 0.1094626\ttotal: 2m 48s\tremaining: 2m 56s\n",
      "488:\tlearn: 0.1094339\ttotal: 2m 48s\tremaining: 2m 56s\n",
      "489:\tlearn: 0.1094072\ttotal: 2m 49s\tremaining: 2m 56s\n",
      "490:\tlearn: 0.1093070\ttotal: 2m 49s\tremaining: 2m 55s\n",
      "491:\tlearn: 0.1092453\ttotal: 2m 49s\tremaining: 2m 55s\n",
      "492:\tlearn: 0.1092187\ttotal: 2m 50s\tremaining: 2m 55s\n",
      "493:\tlearn: 0.1091802\ttotal: 2m 50s\tremaining: 2m 54s\n",
      "494:\tlearn: 0.1091535\ttotal: 2m 50s\tremaining: 2m 54s\n",
      "495:\tlearn: 0.1090750\ttotal: 2m 51s\tremaining: 2m 54s\n",
      "496:\tlearn: 0.1090040\ttotal: 2m 51s\tremaining: 2m 53s\n",
      "497:\tlearn: 0.1089421\ttotal: 2m 51s\tremaining: 2m 53s\n",
      "498:\tlearn: 0.1089157\ttotal: 2m 52s\tremaining: 2m 53s\n",
      "499:\tlearn: 0.1088144\ttotal: 2m 52s\tremaining: 2m 52s\n",
      "500:\tlearn: 0.1087764\ttotal: 2m 53s\tremaining: 2m 52s\n",
      "501:\tlearn: 0.1087503\ttotal: 2m 53s\tremaining: 2m 51s\n",
      "502:\tlearn: 0.1086698\ttotal: 2m 53s\tremaining: 2m 51s\n",
      "503:\tlearn: 0.1085802\ttotal: 2m 54s\tremaining: 2m 51s\n",
      "504:\tlearn: 0.1085494\ttotal: 2m 54s\tremaining: 2m 50s\n",
      "505:\tlearn: 0.1084662\ttotal: 2m 54s\tremaining: 2m 50s\n",
      "506:\tlearn: 0.1084336\ttotal: 2m 55s\tremaining: 2m 50s\n",
      "507:\tlearn: 0.1084065\ttotal: 2m 55s\tremaining: 2m 49s\n",
      "508:\tlearn: 0.1083050\ttotal: 2m 55s\tremaining: 2m 49s\n",
      "509:\tlearn: 0.1082780\ttotal: 2m 56s\tremaining: 2m 49s\n",
      "510:\tlearn: 0.1081170\ttotal: 2m 56s\tremaining: 2m 48s\n",
      "511:\tlearn: 0.1080914\ttotal: 2m 56s\tremaining: 2m 48s\n",
      "512:\tlearn: 0.1080140\ttotal: 2m 57s\tremaining: 2m 48s\n",
      "513:\tlearn: 0.1079405\ttotal: 2m 57s\tremaining: 2m 47s\n",
      "514:\tlearn: 0.1079108\ttotal: 2m 57s\tremaining: 2m 47s\n",
      "515:\tlearn: 0.1078315\ttotal: 2m 58s\tremaining: 2m 47s\n",
      "516:\tlearn: 0.1077472\ttotal: 2m 58s\tremaining: 2m 46s\n",
      "517:\tlearn: 0.1076883\ttotal: 2m 59s\tremaining: 2m 46s\n",
      "518:\tlearn: 0.1076451\ttotal: 2m 59s\tremaining: 2m 46s\n",
      "519:\tlearn: 0.1076030\ttotal: 2m 59s\tremaining: 2m 45s\n",
      "520:\tlearn: 0.1075558\ttotal: 3m\tremaining: 2m 45s\n",
      "521:\tlearn: 0.1074855\ttotal: 3m\tremaining: 2m 45s\n",
      "522:\tlearn: 0.1074592\ttotal: 3m\tremaining: 2m 44s\n",
      "523:\tlearn: 0.1074103\ttotal: 3m 1s\tremaining: 2m 44s\n",
      "524:\tlearn: 0.1073820\ttotal: 3m 1s\tremaining: 2m 44s\n",
      "525:\tlearn: 0.1073157\ttotal: 3m 2s\tremaining: 2m 44s\n",
      "526:\tlearn: 0.1072879\ttotal: 3m 2s\tremaining: 2m 43s\n",
      "527:\tlearn: 0.1072474\ttotal: 3m 2s\tremaining: 2m 43s\n",
      "528:\tlearn: 0.1071873\ttotal: 3m 3s\tremaining: 2m 43s\n",
      "529:\tlearn: 0.1071229\ttotal: 3m 3s\tremaining: 2m 42s\n",
      "530:\tlearn: 0.1070952\ttotal: 3m 3s\tremaining: 2m 42s\n",
      "531:\tlearn: 0.1070022\ttotal: 3m 4s\tremaining: 2m 41s\n",
      "532:\tlearn: 0.1069762\ttotal: 3m 4s\tremaining: 2m 41s\n",
      "533:\tlearn: 0.1069238\ttotal: 3m 4s\tremaining: 2m 41s\n",
      "534:\tlearn: 0.1068664\ttotal: 3m 5s\tremaining: 2m 40s\n",
      "535:\tlearn: 0.1068379\ttotal: 3m 5s\tremaining: 2m 40s\n",
      "536:\tlearn: 0.1067600\ttotal: 3m 5s\tremaining: 2m 40s\n",
      "537:\tlearn: 0.1067327\ttotal: 3m 6s\tremaining: 2m 39s\n",
      "538:\tlearn: 0.1066992\ttotal: 3m 6s\tremaining: 2m 39s\n",
      "539:\tlearn: 0.1065872\ttotal: 3m 6s\tremaining: 2m 39s\n",
      "540:\tlearn: 0.1064915\ttotal: 3m 7s\tremaining: 2m 38s\n",
      "541:\tlearn: 0.1064199\ttotal: 3m 7s\tremaining: 2m 38s\n",
      "542:\tlearn: 0.1063613\ttotal: 3m 7s\tremaining: 2m 38s\n",
      "543:\tlearn: 0.1062288\ttotal: 3m 8s\tremaining: 2m 37s\n",
      "544:\tlearn: 0.1061919\ttotal: 3m 8s\tremaining: 2m 37s\n",
      "545:\tlearn: 0.1061357\ttotal: 3m 9s\tremaining: 2m 37s\n",
      "546:\tlearn: 0.1060996\ttotal: 3m 9s\tremaining: 2m 36s\n",
      "547:\tlearn: 0.1060719\ttotal: 3m 9s\tremaining: 2m 36s\n",
      "548:\tlearn: 0.1060455\ttotal: 3m 10s\tremaining: 2m 36s\n",
      "549:\tlearn: 0.1059916\ttotal: 3m 10s\tremaining: 2m 35s\n",
      "550:\tlearn: 0.1059020\ttotal: 3m 10s\tremaining: 2m 35s\n",
      "551:\tlearn: 0.1058682\ttotal: 3m 11s\tremaining: 2m 35s\n",
      "552:\tlearn: 0.1057480\ttotal: 3m 11s\tremaining: 2m 34s\n",
      "553:\tlearn: 0.1057213\ttotal: 3m 11s\tremaining: 2m 34s\n",
      "554:\tlearn: 0.1056189\ttotal: 3m 12s\tremaining: 2m 34s\n",
      "555:\tlearn: 0.1055613\ttotal: 3m 12s\tremaining: 2m 33s\n",
      "556:\tlearn: 0.1054694\ttotal: 3m 12s\tremaining: 2m 33s\n",
      "557:\tlearn: 0.1054435\ttotal: 3m 13s\tremaining: 2m 33s\n",
      "558:\tlearn: 0.1053938\ttotal: 3m 13s\tremaining: 2m 32s\n",
      "559:\tlearn: 0.1053427\ttotal: 3m 13s\tremaining: 2m 32s\n",
      "560:\tlearn: 0.1052735\ttotal: 3m 14s\tremaining: 2m 32s\n",
      "561:\tlearn: 0.1052394\ttotal: 3m 14s\tremaining: 2m 31s\n",
      "562:\tlearn: 0.1052132\ttotal: 3m 15s\tremaining: 2m 31s\n",
      "563:\tlearn: 0.1051904\ttotal: 3m 15s\tremaining: 2m 31s\n",
      "564:\tlearn: 0.1051383\ttotal: 3m 15s\tremaining: 2m 30s\n",
      "565:\tlearn: 0.1050474\ttotal: 3m 16s\tremaining: 2m 30s\n",
      "566:\tlearn: 0.1049807\ttotal: 3m 16s\tremaining: 2m 29s\n",
      "567:\tlearn: 0.1049123\ttotal: 3m 16s\tremaining: 2m 29s\n",
      "568:\tlearn: 0.1048643\ttotal: 3m 17s\tremaining: 2m 29s\n",
      "569:\tlearn: 0.1048074\ttotal: 3m 17s\tremaining: 2m 28s\n",
      "570:\tlearn: 0.1047828\ttotal: 3m 17s\tremaining: 2m 28s\n",
      "571:\tlearn: 0.1046774\ttotal: 3m 18s\tremaining: 2m 28s\n",
      "572:\tlearn: 0.1046107\ttotal: 3m 18s\tremaining: 2m 27s\n",
      "573:\tlearn: 0.1045763\ttotal: 3m 18s\tremaining: 2m 27s\n",
      "574:\tlearn: 0.1044912\ttotal: 3m 19s\tremaining: 2m 27s\n",
      "575:\tlearn: 0.1044671\ttotal: 3m 19s\tremaining: 2m 26s\n",
      "576:\tlearn: 0.1044294\ttotal: 3m 19s\tremaining: 2m 26s\n",
      "577:\tlearn: 0.1043890\ttotal: 3m 20s\tremaining: 2m 26s\n",
      "578:\tlearn: 0.1043048\ttotal: 3m 20s\tremaining: 2m 25s\n",
      "579:\tlearn: 0.1042785\ttotal: 3m 20s\tremaining: 2m 25s\n",
      "580:\tlearn: 0.1041971\ttotal: 3m 21s\tremaining: 2m 25s\n",
      "581:\tlearn: 0.1041297\ttotal: 3m 21s\tremaining: 2m 24s\n",
      "582:\tlearn: 0.1040410\ttotal: 3m 22s\tremaining: 2m 24s\n",
      "583:\tlearn: 0.1040169\ttotal: 3m 22s\tremaining: 2m 24s\n",
      "584:\tlearn: 0.1039809\ttotal: 3m 22s\tremaining: 2m 23s\n",
      "585:\tlearn: 0.1039430\ttotal: 3m 23s\tremaining: 2m 23s\n",
      "586:\tlearn: 0.1039056\ttotal: 3m 23s\tremaining: 2m 23s\n",
      "587:\tlearn: 0.1038340\ttotal: 3m 23s\tremaining: 2m 22s\n",
      "588:\tlearn: 0.1037564\ttotal: 3m 24s\tremaining: 2m 22s\n",
      "589:\tlearn: 0.1036971\ttotal: 3m 24s\tremaining: 2m 22s\n",
      "590:\tlearn: 0.1036668\ttotal: 3m 24s\tremaining: 2m 21s\n",
      "591:\tlearn: 0.1035179\ttotal: 3m 25s\tremaining: 2m 21s\n",
      "592:\tlearn: 0.1034612\ttotal: 3m 25s\tremaining: 2m 21s\n",
      "593:\tlearn: 0.1034370\ttotal: 3m 25s\tremaining: 2m 20s\n",
      "594:\tlearn: 0.1034040\ttotal: 3m 26s\tremaining: 2m 20s\n",
      "595:\tlearn: 0.1033803\ttotal: 3m 26s\tremaining: 2m 19s\n",
      "596:\tlearn: 0.1033165\ttotal: 3m 26s\tremaining: 2m 19s\n",
      "597:\tlearn: 0.1032394\ttotal: 3m 27s\tremaining: 2m 19s\n",
      "598:\tlearn: 0.1032059\ttotal: 3m 27s\tremaining: 2m 18s\n",
      "599:\tlearn: 0.1031705\ttotal: 3m 27s\tremaining: 2m 18s\n",
      "600:\tlearn: 0.1030703\ttotal: 3m 28s\tremaining: 2m 18s\n",
      "601:\tlearn: 0.1030440\ttotal: 3m 28s\tremaining: 2m 17s\n",
      "602:\tlearn: 0.1029539\ttotal: 3m 28s\tremaining: 2m 17s\n",
      "603:\tlearn: 0.1029297\ttotal: 3m 29s\tremaining: 2m 17s\n",
      "604:\tlearn: 0.1029070\ttotal: 3m 29s\tremaining: 2m 16s\n",
      "605:\tlearn: 0.1028726\ttotal: 3m 30s\tremaining: 2m 16s\n",
      "606:\tlearn: 0.1028492\ttotal: 3m 30s\tremaining: 2m 16s\n",
      "607:\tlearn: 0.1027801\ttotal: 3m 30s\tremaining: 2m 15s\n",
      "608:\tlearn: 0.1027145\ttotal: 3m 31s\tremaining: 2m 15s\n",
      "609:\tlearn: 0.1026853\ttotal: 3m 31s\tremaining: 2m 15s\n",
      "610:\tlearn: 0.1025940\ttotal: 3m 31s\tremaining: 2m 14s\n",
      "611:\tlearn: 0.1025341\ttotal: 3m 32s\tremaining: 2m 14s\n",
      "612:\tlearn: 0.1024278\ttotal: 3m 32s\tremaining: 2m 14s\n",
      "613:\tlearn: 0.1024020\ttotal: 3m 32s\tremaining: 2m 13s\n",
      "614:\tlearn: 0.1023611\ttotal: 3m 33s\tremaining: 2m 13s\n",
      "615:\tlearn: 0.1023088\ttotal: 3m 33s\tremaining: 2m 13s\n",
      "616:\tlearn: 0.1022385\ttotal: 3m 33s\tremaining: 2m 12s\n",
      "617:\tlearn: 0.1021983\ttotal: 3m 34s\tremaining: 2m 12s\n",
      "618:\tlearn: 0.1021763\ttotal: 3m 34s\tremaining: 2m 12s\n",
      "619:\tlearn: 0.1021497\ttotal: 3m 34s\tremaining: 2m 11s\n",
      "620:\tlearn: 0.1020875\ttotal: 3m 35s\tremaining: 2m 11s\n",
      "621:\tlearn: 0.1020227\ttotal: 3m 35s\tremaining: 2m 11s\n",
      "622:\tlearn: 0.1019865\ttotal: 3m 35s\tremaining: 2m 10s\n",
      "623:\tlearn: 0.1019653\ttotal: 3m 36s\tremaining: 2m 10s\n",
      "624:\tlearn: 0.1019430\ttotal: 3m 36s\tremaining: 2m 9s\n",
      "625:\tlearn: 0.1019184\ttotal: 3m 36s\tremaining: 2m 9s\n",
      "626:\tlearn: 0.1018468\ttotal: 3m 37s\tremaining: 2m 9s\n",
      "627:\tlearn: 0.1018161\ttotal: 3m 37s\tremaining: 2m 8s\n",
      "628:\tlearn: 0.1017373\ttotal: 3m 37s\tremaining: 2m 8s\n",
      "629:\tlearn: 0.1017147\ttotal: 3m 38s\tremaining: 2m 8s\n",
      "630:\tlearn: 0.1016923\ttotal: 3m 38s\tremaining: 2m 7s\n",
      "631:\tlearn: 0.1016700\ttotal: 3m 38s\tremaining: 2m 7s\n",
      "632:\tlearn: 0.1016178\ttotal: 3m 39s\tremaining: 2m 7s\n",
      "633:\tlearn: 0.1015782\ttotal: 3m 39s\tremaining: 2m 6s\n",
      "634:\tlearn: 0.1015336\ttotal: 3m 39s\tremaining: 2m 6s\n",
      "635:\tlearn: 0.1014798\ttotal: 3m 40s\tremaining: 2m 6s\n",
      "636:\tlearn: 0.1014585\ttotal: 3m 40s\tremaining: 2m 5s\n",
      "637:\tlearn: 0.1014367\ttotal: 3m 40s\tremaining: 2m 5s\n",
      "638:\tlearn: 0.1013655\ttotal: 3m 41s\tremaining: 2m 5s\n",
      "639:\tlearn: 0.1013422\ttotal: 3m 41s\tremaining: 2m 4s\n",
      "640:\tlearn: 0.1013049\ttotal: 3m 41s\tremaining: 2m 4s\n",
      "641:\tlearn: 0.1012798\ttotal: 3m 42s\tremaining: 2m 3s\n",
      "642:\tlearn: 0.1012457\ttotal: 3m 42s\tremaining: 2m 3s\n",
      "643:\tlearn: 0.1011712\ttotal: 3m 43s\tremaining: 2m 3s\n",
      "644:\tlearn: 0.1011491\ttotal: 3m 43s\tremaining: 2m 2s\n",
      "645:\tlearn: 0.1011262\ttotal: 3m 43s\tremaining: 2m 2s\n",
      "646:\tlearn: 0.1010738\ttotal: 3m 44s\tremaining: 2m 2s\n",
      "647:\tlearn: 0.1010524\ttotal: 3m 44s\tremaining: 2m 1s\n",
      "648:\tlearn: 0.1010244\ttotal: 3m 44s\tremaining: 2m 1s\n",
      "649:\tlearn: 0.1010031\ttotal: 3m 45s\tremaining: 2m 1s\n",
      "650:\tlearn: 0.1009757\ttotal: 3m 45s\tremaining: 2m\n",
      "651:\tlearn: 0.1009545\ttotal: 3m 45s\tremaining: 2m\n",
      "652:\tlearn: 0.1009330\ttotal: 3m 46s\tremaining: 2m\n",
      "653:\tlearn: 0.1008751\ttotal: 3m 46s\tremaining: 1m 59s\n",
      "654:\tlearn: 0.1008545\ttotal: 3m 46s\tremaining: 1m 59s\n",
      "655:\tlearn: 0.1007974\ttotal: 3m 47s\tremaining: 1m 59s\n",
      "656:\tlearn: 0.1007760\ttotal: 3m 47s\tremaining: 1m 58s\n",
      "657:\tlearn: 0.1007551\ttotal: 3m 48s\tremaining: 1m 58s\n",
      "658:\tlearn: 0.1007319\ttotal: 3m 48s\tremaining: 1m 58s\n",
      "659:\tlearn: 0.1006972\ttotal: 3m 48s\tremaining: 1m 57s\n",
      "660:\tlearn: 0.1006453\ttotal: 3m 49s\tremaining: 1m 57s\n",
      "661:\tlearn: 0.1005877\ttotal: 3m 49s\tremaining: 1m 57s\n",
      "662:\tlearn: 0.1005695\ttotal: 3m 49s\tremaining: 1m 56s\n",
      "663:\tlearn: 0.1004665\ttotal: 3m 50s\tremaining: 1m 56s\n",
      "664:\tlearn: 0.1004204\ttotal: 3m 50s\tremaining: 1m 56s\n",
      "665:\tlearn: 0.1003541\ttotal: 3m 50s\tremaining: 1m 55s\n",
      "666:\tlearn: 0.1003334\ttotal: 3m 51s\tremaining: 1m 55s\n",
      "667:\tlearn: 0.1003127\ttotal: 3m 51s\tremaining: 1m 55s\n",
      "668:\tlearn: 0.1002923\ttotal: 3m 51s\tremaining: 1m 54s\n",
      "669:\tlearn: 0.1002719\ttotal: 3m 52s\tremaining: 1m 54s\n",
      "670:\tlearn: 0.1002526\ttotal: 3m 52s\tremaining: 1m 54s\n",
      "671:\tlearn: 0.1002318\ttotal: 3m 52s\tremaining: 1m 53s\n",
      "672:\tlearn: 0.1001718\ttotal: 3m 53s\tremaining: 1m 53s\n",
      "673:\tlearn: 0.1001514\ttotal: 3m 53s\tremaining: 1m 52s\n",
      "674:\tlearn: 0.1001235\ttotal: 3m 53s\tremaining: 1m 52s\n",
      "675:\tlearn: 0.1001041\ttotal: 3m 54s\tremaining: 1m 52s\n",
      "676:\tlearn: 0.1000838\ttotal: 3m 54s\tremaining: 1m 51s\n",
      "677:\tlearn: 0.1000557\ttotal: 3m 54s\tremaining: 1m 51s\n",
      "678:\tlearn: 0.1000278\ttotal: 3m 55s\tremaining: 1m 51s\n",
      "679:\tlearn: 0.1000058\ttotal: 3m 55s\tremaining: 1m 50s\n",
      "680:\tlearn: 0.0999604\ttotal: 3m 56s\tremaining: 1m 50s\n",
      "681:\tlearn: 0.0999089\ttotal: 3m 56s\tremaining: 1m 50s\n",
      "682:\tlearn: 0.0998869\ttotal: 3m 56s\tremaining: 1m 49s\n",
      "683:\tlearn: 0.0998670\ttotal: 3m 57s\tremaining: 1m 49s\n",
      "684:\tlearn: 0.0998473\ttotal: 3m 57s\tremaining: 1m 49s\n",
      "685:\tlearn: 0.0997846\ttotal: 3m 57s\tremaining: 1m 48s\n",
      "686:\tlearn: 0.0997645\ttotal: 3m 58s\tremaining: 1m 48s\n",
      "687:\tlearn: 0.0996722\ttotal: 3m 58s\tremaining: 1m 48s\n",
      "688:\tlearn: 0.0996063\ttotal: 3m 58s\tremaining: 1m 47s\n",
      "689:\tlearn: 0.0995807\ttotal: 3m 59s\tremaining: 1m 47s\n",
      "690:\tlearn: 0.0995517\ttotal: 3m 59s\tremaining: 1m 47s\n",
      "691:\tlearn: 0.0995221\ttotal: 3m 59s\tremaining: 1m 46s\n",
      "692:\tlearn: 0.0994915\ttotal: 4m\tremaining: 1m 46s\n",
      "693:\tlearn: 0.0994288\ttotal: 4m\tremaining: 1m 46s\n",
      "694:\tlearn: 0.0994097\ttotal: 4m\tremaining: 1m 45s\n",
      "695:\tlearn: 0.0993898\ttotal: 4m 1s\tremaining: 1m 45s\n",
      "696:\tlearn: 0.0993243\ttotal: 4m 1s\tremaining: 1m 45s\n",
      "697:\tlearn: 0.0993057\ttotal: 4m 1s\tremaining: 1m 44s\n",
      "698:\tlearn: 0.0992838\ttotal: 4m 2s\tremaining: 1m 44s\n",
      "699:\tlearn: 0.0992494\ttotal: 4m 2s\tremaining: 1m 44s\n",
      "700:\tlearn: 0.0992292\ttotal: 4m 3s\tremaining: 1m 43s\n",
      "701:\tlearn: 0.0992095\ttotal: 4m 3s\tremaining: 1m 43s\n",
      "702:\tlearn: 0.0991486\ttotal: 4m 3s\tremaining: 1m 42s\n",
      "703:\tlearn: 0.0991084\ttotal: 4m 4s\tremaining: 1m 42s\n",
      "704:\tlearn: 0.0990883\ttotal: 4m 4s\tremaining: 1m 42s\n",
      "705:\tlearn: 0.0990618\ttotal: 4m 4s\tremaining: 1m 41s\n",
      "706:\tlearn: 0.0989933\ttotal: 4m 5s\tremaining: 1m 41s\n",
      "707:\tlearn: 0.0989350\ttotal: 4m 5s\tremaining: 1m 41s\n",
      "708:\tlearn: 0.0988754\ttotal: 4m 5s\tremaining: 1m 40s\n",
      "709:\tlearn: 0.0988537\ttotal: 4m 6s\tremaining: 1m 40s\n",
      "710:\tlearn: 0.0988340\ttotal: 4m 6s\tremaining: 1m 40s\n",
      "711:\tlearn: 0.0988156\ttotal: 4m 6s\tremaining: 1m 39s\n",
      "712:\tlearn: 0.0987959\ttotal: 4m 7s\tremaining: 1m 39s\n",
      "713:\tlearn: 0.0987764\ttotal: 4m 7s\tremaining: 1m 39s\n",
      "714:\tlearn: 0.0987568\ttotal: 4m 7s\tremaining: 1m 38s\n",
      "715:\tlearn: 0.0987360\ttotal: 4m 8s\tremaining: 1m 38s\n",
      "716:\tlearn: 0.0987171\ttotal: 4m 8s\tremaining: 1m 38s\n",
      "717:\tlearn: 0.0986983\ttotal: 4m 9s\tremaining: 1m 37s\n",
      "718:\tlearn: 0.0986255\ttotal: 4m 9s\tremaining: 1m 37s\n",
      "719:\tlearn: 0.0986029\ttotal: 4m 9s\tremaining: 1m 37s\n",
      "720:\tlearn: 0.0985837\ttotal: 4m 10s\tremaining: 1m 36s\n",
      "721:\tlearn: 0.0985648\ttotal: 4m 10s\tremaining: 1m 36s\n",
      "722:\tlearn: 0.0985459\ttotal: 4m 10s\tremaining: 1m 36s\n",
      "723:\tlearn: 0.0985242\ttotal: 4m 11s\tremaining: 1m 35s\n",
      "724:\tlearn: 0.0985045\ttotal: 4m 11s\tremaining: 1m 35s\n",
      "725:\tlearn: 0.0984851\ttotal: 4m 11s\tremaining: 1m 35s\n",
      "726:\tlearn: 0.0984289\ttotal: 4m 12s\tremaining: 1m 34s\n",
      "727:\tlearn: 0.0983738\ttotal: 4m 12s\tremaining: 1m 34s\n",
      "728:\tlearn: 0.0983212\ttotal: 4m 12s\tremaining: 1m 33s\n",
      "729:\tlearn: 0.0983025\ttotal: 4m 13s\tremaining: 1m 33s\n",
      "730:\tlearn: 0.0982838\ttotal: 4m 13s\tremaining: 1m 33s\n",
      "731:\tlearn: 0.0982645\ttotal: 4m 13s\tremaining: 1m 32s\n",
      "732:\tlearn: 0.0982453\ttotal: 4m 14s\tremaining: 1m 32s\n",
      "733:\tlearn: 0.0982245\ttotal: 4m 14s\tremaining: 1m 32s\n",
      "734:\tlearn: 0.0982060\ttotal: 4m 14s\tremaining: 1m 31s\n",
      "735:\tlearn: 0.0981876\ttotal: 4m 15s\tremaining: 1m 31s\n",
      "736:\tlearn: 0.0981265\ttotal: 4m 15s\tremaining: 1m 31s\n",
      "737:\tlearn: 0.0981086\ttotal: 4m 15s\tremaining: 1m 30s\n",
      "738:\tlearn: 0.0980455\ttotal: 4m 16s\tremaining: 1m 30s\n",
      "739:\tlearn: 0.0980274\ttotal: 4m 16s\tremaining: 1m 30s\n",
      "740:\tlearn: 0.0979726\ttotal: 4m 16s\tremaining: 1m 29s\n",
      "741:\tlearn: 0.0979425\ttotal: 4m 17s\tremaining: 1m 29s\n",
      "742:\tlearn: 0.0979241\ttotal: 4m 17s\tremaining: 1m 29s\n",
      "743:\tlearn: 0.0978659\ttotal: 4m 18s\tremaining: 1m 28s\n",
      "744:\tlearn: 0.0977617\ttotal: 4m 18s\tremaining: 1m 28s\n",
      "745:\tlearn: 0.0977435\ttotal: 4m 18s\tremaining: 1m 28s\n",
      "746:\tlearn: 0.0977251\ttotal: 4m 19s\tremaining: 1m 27s\n",
      "747:\tlearn: 0.0977059\ttotal: 4m 19s\tremaining: 1m 27s\n",
      "748:\tlearn: 0.0976871\ttotal: 4m 19s\tremaining: 1m 27s\n",
      "749:\tlearn: 0.0976238\ttotal: 4m 20s\tremaining: 1m 26s\n",
      "750:\tlearn: 0.0975266\ttotal: 4m 20s\tremaining: 1m 26s\n",
      "751:\tlearn: 0.0975078\ttotal: 4m 20s\tremaining: 1m 26s\n",
      "752:\tlearn: 0.0974887\ttotal: 4m 21s\tremaining: 1m 25s\n",
      "753:\tlearn: 0.0974708\ttotal: 4m 21s\tremaining: 1m 25s\n",
      "754:\tlearn: 0.0974522\ttotal: 4m 21s\tremaining: 1m 24s\n",
      "755:\tlearn: 0.0974339\ttotal: 4m 22s\tremaining: 1m 24s\n",
      "756:\tlearn: 0.0973938\ttotal: 4m 22s\tremaining: 1m 24s\n",
      "757:\tlearn: 0.0973745\ttotal: 4m 22s\tremaining: 1m 23s\n",
      "758:\tlearn: 0.0973565\ttotal: 4m 23s\tremaining: 1m 23s\n",
      "759:\tlearn: 0.0973382\ttotal: 4m 23s\tremaining: 1m 23s\n",
      "760:\tlearn: 0.0973193\ttotal: 4m 23s\tremaining: 1m 22s\n",
      "761:\tlearn: 0.0973010\ttotal: 4m 24s\tremaining: 1m 22s\n",
      "762:\tlearn: 0.0972820\ttotal: 4m 24s\tremaining: 1m 22s\n",
      "763:\tlearn: 0.0972635\ttotal: 4m 25s\tremaining: 1m 21s\n",
      "764:\tlearn: 0.0972469\ttotal: 4m 25s\tremaining: 1m 21s\n",
      "765:\tlearn: 0.0972280\ttotal: 4m 25s\tremaining: 1m 21s\n",
      "766:\tlearn: 0.0972104\ttotal: 4m 26s\tremaining: 1m 20s\n",
      "767:\tlearn: 0.0971916\ttotal: 4m 26s\tremaining: 1m 20s\n",
      "768:\tlearn: 0.0971523\ttotal: 4m 26s\tremaining: 1m 20s\n",
      "769:\tlearn: 0.0971343\ttotal: 4m 27s\tremaining: 1m 19s\n",
      "770:\tlearn: 0.0970837\ttotal: 4m 27s\tremaining: 1m 19s\n",
      "771:\tlearn: 0.0970408\ttotal: 4m 27s\tremaining: 1m 19s\n",
      "772:\tlearn: 0.0970226\ttotal: 4m 28s\tremaining: 1m 18s\n",
      "773:\tlearn: 0.0969941\ttotal: 4m 28s\tremaining: 1m 18s\n",
      "774:\tlearn: 0.0969758\ttotal: 4m 28s\tremaining: 1m 18s\n",
      "775:\tlearn: 0.0969580\ttotal: 4m 29s\tremaining: 1m 17s\n",
      "776:\tlearn: 0.0969202\ttotal: 4m 29s\tremaining: 1m 17s\n",
      "777:\tlearn: 0.0969021\ttotal: 4m 29s\tremaining: 1m 17s\n",
      "778:\tlearn: 0.0968840\ttotal: 4m 30s\tremaining: 1m 16s\n",
      "779:\tlearn: 0.0968655\ttotal: 4m 30s\tremaining: 1m 16s\n",
      "780:\tlearn: 0.0968042\ttotal: 4m 30s\tremaining: 1m 15s\n",
      "781:\tlearn: 0.0967775\ttotal: 4m 31s\tremaining: 1m 15s\n",
      "782:\tlearn: 0.0967230\ttotal: 4m 31s\tremaining: 1m 15s\n",
      "783:\tlearn: 0.0967022\ttotal: 4m 31s\tremaining: 1m 14s\n",
      "784:\tlearn: 0.0966841\ttotal: 4m 32s\tremaining: 1m 14s\n",
      "785:\tlearn: 0.0966657\ttotal: 4m 32s\tremaining: 1m 14s\n",
      "786:\tlearn: 0.0966474\ttotal: 4m 33s\tremaining: 1m 13s\n",
      "787:\tlearn: 0.0966290\ttotal: 4m 33s\tremaining: 1m 13s\n",
      "788:\tlearn: 0.0966106\ttotal: 4m 33s\tremaining: 1m 13s\n",
      "789:\tlearn: 0.0965928\ttotal: 4m 34s\tremaining: 1m 12s\n",
      "790:\tlearn: 0.0965341\ttotal: 4m 34s\tremaining: 1m 12s\n",
      "791:\tlearn: 0.0965130\ttotal: 4m 34s\tremaining: 1m 12s\n",
      "792:\tlearn: 0.0964887\ttotal: 4m 35s\tremaining: 1m 11s\n",
      "793:\tlearn: 0.0964315\ttotal: 4m 35s\tremaining: 1m 11s\n",
      "794:\tlearn: 0.0964134\ttotal: 4m 35s\tremaining: 1m 11s\n",
      "795:\tlearn: 0.0963961\ttotal: 4m 36s\tremaining: 1m 10s\n",
      "796:\tlearn: 0.0963783\ttotal: 4m 36s\tremaining: 1m 10s\n",
      "797:\tlearn: 0.0963597\ttotal: 4m 36s\tremaining: 1m 10s\n",
      "798:\tlearn: 0.0963195\ttotal: 4m 37s\tremaining: 1m 9s\n",
      "799:\tlearn: 0.0962947\ttotal: 4m 37s\tremaining: 1m 9s\n",
      "800:\tlearn: 0.0962771\ttotal: 4m 37s\tremaining: 1m 9s\n",
      "801:\tlearn: 0.0962605\ttotal: 4m 38s\tremaining: 1m 8s\n",
      "802:\tlearn: 0.0962424\ttotal: 4m 38s\tremaining: 1m 8s\n",
      "803:\tlearn: 0.0962242\ttotal: 4m 39s\tremaining: 1m 8s\n",
      "804:\tlearn: 0.0962071\ttotal: 4m 39s\tremaining: 1m 7s\n",
      "805:\tlearn: 0.0961896\ttotal: 4m 39s\tremaining: 1m 7s\n",
      "806:\tlearn: 0.0961720\ttotal: 4m 40s\tremaining: 1m 7s\n",
      "807:\tlearn: 0.0961548\ttotal: 4m 40s\tremaining: 1m 6s\n",
      "808:\tlearn: 0.0961368\ttotal: 4m 40s\tremaining: 1m 6s\n",
      "809:\tlearn: 0.0961187\ttotal: 4m 41s\tremaining: 1m 5s\n",
      "810:\tlearn: 0.0961007\ttotal: 4m 41s\tremaining: 1m 5s\n",
      "811:\tlearn: 0.0960832\ttotal: 4m 41s\tremaining: 1m 5s\n",
      "812:\tlearn: 0.0960620\ttotal: 4m 42s\tremaining: 1m 4s\n",
      "813:\tlearn: 0.0959975\ttotal: 4m 42s\tremaining: 1m 4s\n",
      "814:\tlearn: 0.0959773\ttotal: 4m 43s\tremaining: 1m 4s\n",
      "815:\tlearn: 0.0959592\ttotal: 4m 43s\tremaining: 1m 3s\n",
      "816:\tlearn: 0.0959418\ttotal: 4m 43s\tremaining: 1m 3s\n",
      "817:\tlearn: 0.0959254\ttotal: 4m 44s\tremaining: 1m 3s\n",
      "818:\tlearn: 0.0959075\ttotal: 4m 44s\tremaining: 1m 2s\n",
      "819:\tlearn: 0.0958909\ttotal: 4m 44s\tremaining: 1m 2s\n",
      "820:\tlearn: 0.0958732\ttotal: 4m 45s\tremaining: 1m 2s\n",
      "821:\tlearn: 0.0958528\ttotal: 4m 45s\tremaining: 1m 1s\n",
      "822:\tlearn: 0.0958350\ttotal: 4m 45s\tremaining: 1m 1s\n",
      "823:\tlearn: 0.0958178\ttotal: 4m 46s\tremaining: 1m 1s\n",
      "824:\tlearn: 0.0958013\ttotal: 4m 46s\tremaining: 1m\n",
      "825:\tlearn: 0.0957412\ttotal: 4m 46s\tremaining: 1m\n",
      "826:\tlearn: 0.0957242\ttotal: 4m 47s\tremaining: 1m\n",
      "827:\tlearn: 0.0956688\ttotal: 4m 47s\tremaining: 59.8s\n",
      "828:\tlearn: 0.0956488\ttotal: 4m 47s\tremaining: 59.4s\n",
      "829:\tlearn: 0.0956309\ttotal: 4m 48s\tremaining: 59.1s\n",
      "830:\tlearn: 0.0955899\ttotal: 4m 48s\tremaining: 58.7s\n",
      "831:\tlearn: 0.0955725\ttotal: 4m 49s\tremaining: 58.4s\n",
      "832:\tlearn: 0.0955553\ttotal: 4m 49s\tremaining: 58s\n",
      "833:\tlearn: 0.0955376\ttotal: 4m 49s\tremaining: 57.7s\n",
      "834:\tlearn: 0.0955199\ttotal: 4m 50s\tremaining: 57.3s\n",
      "835:\tlearn: 0.0955036\ttotal: 4m 50s\tremaining: 57s\n",
      "836:\tlearn: 0.0954860\ttotal: 4m 50s\tremaining: 56.6s\n",
      "837:\tlearn: 0.0954683\ttotal: 4m 51s\tremaining: 56.3s\n",
      "838:\tlearn: 0.0954512\ttotal: 4m 51s\tremaining: 55.9s\n",
      "839:\tlearn: 0.0954341\ttotal: 4m 51s\tremaining: 55.6s\n",
      "840:\tlearn: 0.0954161\ttotal: 4m 52s\tremaining: 55.2s\n",
      "841:\tlearn: 0.0953990\ttotal: 4m 52s\tremaining: 54.9s\n",
      "842:\tlearn: 0.0953256\ttotal: 4m 52s\tremaining: 54.5s\n",
      "843:\tlearn: 0.0952380\ttotal: 4m 53s\tremaining: 54.2s\n",
      "844:\tlearn: 0.0951648\ttotal: 4m 53s\tremaining: 53.9s\n",
      "845:\tlearn: 0.0951473\ttotal: 4m 53s\tremaining: 53.5s\n",
      "846:\tlearn: 0.0951303\ttotal: 4m 54s\tremaining: 53.2s\n",
      "847:\tlearn: 0.0951022\ttotal: 4m 54s\tremaining: 52.8s\n",
      "848:\tlearn: 0.0950852\ttotal: 4m 54s\tremaining: 52.5s\n",
      "849:\tlearn: 0.0950703\ttotal: 4m 55s\tremaining: 52.1s\n",
      "850:\tlearn: 0.0950144\ttotal: 4m 55s\tremaining: 51.8s\n",
      "851:\tlearn: 0.0949687\ttotal: 4m 55s\tremaining: 51.4s\n",
      "852:\tlearn: 0.0949509\ttotal: 4m 56s\tremaining: 51.1s\n",
      "853:\tlearn: 0.0949141\ttotal: 4m 56s\tremaining: 50.7s\n",
      "854:\tlearn: 0.0948971\ttotal: 4m 57s\tremaining: 50.4s\n",
      "855:\tlearn: 0.0948796\ttotal: 4m 57s\tremaining: 50s\n",
      "856:\tlearn: 0.0948626\ttotal: 4m 57s\tremaining: 49.7s\n",
      "857:\tlearn: 0.0948455\ttotal: 4m 58s\tremaining: 49.3s\n",
      "858:\tlearn: 0.0948281\ttotal: 4m 58s\tremaining: 49s\n",
      "859:\tlearn: 0.0948107\ttotal: 4m 58s\tremaining: 48.6s\n",
      "860:\tlearn: 0.0947516\ttotal: 4m 59s\tremaining: 48.3s\n",
      "861:\tlearn: 0.0947345\ttotal: 4m 59s\tremaining: 47.9s\n",
      "862:\tlearn: 0.0947171\ttotal: 4m 59s\tremaining: 47.6s\n",
      "863:\tlearn: 0.0947001\ttotal: 5m\tremaining: 47.2s\n",
      "864:\tlearn: 0.0946835\ttotal: 5m\tremaining: 46.9s\n",
      "865:\tlearn: 0.0946662\ttotal: 5m\tremaining: 46.5s\n",
      "866:\tlearn: 0.0946256\ttotal: 5m 1s\tremaining: 46.2s\n",
      "867:\tlearn: 0.0946101\ttotal: 5m 1s\tremaining: 45.9s\n",
      "868:\tlearn: 0.0945933\ttotal: 5m 1s\tremaining: 45.5s\n",
      "869:\tlearn: 0.0945762\ttotal: 5m 2s\tremaining: 45.2s\n",
      "870:\tlearn: 0.0945585\ttotal: 5m 2s\tremaining: 44.8s\n",
      "871:\tlearn: 0.0945430\ttotal: 5m 2s\tremaining: 44.5s\n",
      "872:\tlearn: 0.0945255\ttotal: 5m 3s\tremaining: 44.1s\n",
      "873:\tlearn: 0.0944455\ttotal: 5m 3s\tremaining: 43.8s\n",
      "874:\tlearn: 0.0944243\ttotal: 5m 3s\tremaining: 43.4s\n",
      "875:\tlearn: 0.0944068\ttotal: 5m 4s\tremaining: 43.1s\n",
      "876:\tlearn: 0.0943579\ttotal: 5m 4s\tremaining: 42.7s\n",
      "877:\tlearn: 0.0943203\ttotal: 5m 4s\tremaining: 42.4s\n",
      "878:\tlearn: 0.0943040\ttotal: 5m 5s\tremaining: 42s\n",
      "879:\tlearn: 0.0942581\ttotal: 5m 5s\tremaining: 41.7s\n",
      "880:\tlearn: 0.0942424\ttotal: 5m 6s\tremaining: 41.3s\n",
      "881:\tlearn: 0.0942226\ttotal: 5m 6s\tremaining: 41s\n",
      "882:\tlearn: 0.0942053\ttotal: 5m 6s\tremaining: 40.6s\n",
      "883:\tlearn: 0.0941473\ttotal: 5m 7s\tremaining: 40.3s\n",
      "884:\tlearn: 0.0941251\ttotal: 5m 7s\tremaining: 40s\n",
      "885:\tlearn: 0.0941075\ttotal: 5m 7s\tremaining: 39.6s\n",
      "886:\tlearn: 0.0940903\ttotal: 5m 8s\tremaining: 39.3s\n",
      "887:\tlearn: 0.0940732\ttotal: 5m 8s\tremaining: 38.9s\n",
      "888:\tlearn: 0.0940557\ttotal: 5m 8s\tremaining: 38.6s\n",
      "889:\tlearn: 0.0940385\ttotal: 5m 9s\tremaining: 38.2s\n",
      "890:\tlearn: 0.0940225\ttotal: 5m 9s\tremaining: 37.9s\n",
      "891:\tlearn: 0.0940050\ttotal: 5m 9s\tremaining: 37.5s\n",
      "892:\tlearn: 0.0939891\ttotal: 5m 10s\tremaining: 37.2s\n",
      "893:\tlearn: 0.0939643\ttotal: 5m 10s\tremaining: 36.8s\n",
      "894:\tlearn: 0.0939237\ttotal: 5m 10s\tremaining: 36.5s\n",
      "895:\tlearn: 0.0939071\ttotal: 5m 11s\tremaining: 36.1s\n",
      "896:\tlearn: 0.0938898\ttotal: 5m 11s\tremaining: 35.8s\n",
      "897:\tlearn: 0.0938733\ttotal: 5m 11s\tremaining: 35.4s\n",
      "898:\tlearn: 0.0938568\ttotal: 5m 12s\tremaining: 35.1s\n",
      "899:\tlearn: 0.0938404\ttotal: 5m 12s\tremaining: 34.7s\n",
      "900:\tlearn: 0.0938237\ttotal: 5m 12s\tremaining: 34.4s\n",
      "901:\tlearn: 0.0938074\ttotal: 5m 13s\tremaining: 34s\n",
      "902:\tlearn: 0.0937837\ttotal: 5m 13s\tremaining: 33.7s\n",
      "903:\tlearn: 0.0937673\ttotal: 5m 14s\tremaining: 33.3s\n",
      "904:\tlearn: 0.0937507\ttotal: 5m 14s\tremaining: 33s\n",
      "905:\tlearn: 0.0937340\ttotal: 5m 14s\tremaining: 32.6s\n",
      "906:\tlearn: 0.0937169\ttotal: 5m 15s\tremaining: 32.3s\n",
      "907:\tlearn: 0.0937004\ttotal: 5m 15s\tremaining: 32s\n",
      "908:\tlearn: 0.0936840\ttotal: 5m 15s\tremaining: 31.6s\n",
      "909:\tlearn: 0.0936673\ttotal: 5m 16s\tremaining: 31.3s\n",
      "910:\tlearn: 0.0936505\ttotal: 5m 16s\tremaining: 30.9s\n",
      "911:\tlearn: 0.0936148\ttotal: 5m 16s\tremaining: 30.6s\n",
      "912:\tlearn: 0.0935984\ttotal: 5m 17s\tremaining: 30.2s\n",
      "913:\tlearn: 0.0935528\ttotal: 5m 17s\tremaining: 29.9s\n",
      "914:\tlearn: 0.0935365\ttotal: 5m 17s\tremaining: 29.5s\n",
      "915:\tlearn: 0.0935199\ttotal: 5m 18s\tremaining: 29.2s\n",
      "916:\tlearn: 0.0935031\ttotal: 5m 18s\tremaining: 28.8s\n",
      "917:\tlearn: 0.0934882\ttotal: 5m 18s\tremaining: 28.5s\n",
      "918:\tlearn: 0.0934716\ttotal: 5m 19s\tremaining: 28.1s\n",
      "919:\tlearn: 0.0934516\ttotal: 5m 19s\tremaining: 27.8s\n",
      "920:\tlearn: 0.0934356\ttotal: 5m 19s\tremaining: 27.4s\n",
      "921:\tlearn: 0.0934198\ttotal: 5m 20s\tremaining: 27.1s\n",
      "922:\tlearn: 0.0934033\ttotal: 5m 20s\tremaining: 26.7s\n",
      "923:\tlearn: 0.0933864\ttotal: 5m 20s\tremaining: 26.4s\n",
      "924:\tlearn: 0.0933702\ttotal: 5m 21s\tremaining: 26s\n",
      "925:\tlearn: 0.0933549\ttotal: 5m 21s\tremaining: 25.7s\n",
      "926:\tlearn: 0.0932983\ttotal: 5m 21s\tremaining: 25.4s\n",
      "927:\tlearn: 0.0932820\ttotal: 5m 22s\tremaining: 25s\n",
      "928:\tlearn: 0.0932659\ttotal: 5m 22s\tremaining: 24.7s\n",
      "929:\tlearn: 0.0932494\ttotal: 5m 23s\tremaining: 24.3s\n",
      "930:\tlearn: 0.0932144\ttotal: 5m 23s\tremaining: 24s\n",
      "931:\tlearn: 0.0931977\ttotal: 5m 23s\tremaining: 23.6s\n",
      "932:\tlearn: 0.0931823\ttotal: 5m 24s\tremaining: 23.3s\n",
      "933:\tlearn: 0.0931659\ttotal: 5m 24s\tremaining: 22.9s\n",
      "934:\tlearn: 0.0931497\ttotal: 5m 24s\tremaining: 22.6s\n",
      "935:\tlearn: 0.0931074\ttotal: 5m 25s\tremaining: 22.2s\n",
      "936:\tlearn: 0.0930913\ttotal: 5m 25s\tremaining: 21.9s\n",
      "937:\tlearn: 0.0930752\ttotal: 5m 25s\tremaining: 21.5s\n",
      "938:\tlearn: 0.0930352\ttotal: 5m 26s\tremaining: 21.2s\n",
      "939:\tlearn: 0.0930192\ttotal: 5m 26s\tremaining: 20.8s\n",
      "940:\tlearn: 0.0929659\ttotal: 5m 26s\tremaining: 20.5s\n",
      "941:\tlearn: 0.0929495\ttotal: 5m 27s\tremaining: 20.1s\n",
      "942:\tlearn: 0.0928975\ttotal: 5m 27s\tremaining: 19.8s\n",
      "943:\tlearn: 0.0928822\ttotal: 5m 27s\tremaining: 19.4s\n",
      "944:\tlearn: 0.0928660\ttotal: 5m 28s\tremaining: 19.1s\n",
      "945:\tlearn: 0.0928496\ttotal: 5m 28s\tremaining: 18.8s\n",
      "946:\tlearn: 0.0927835\ttotal: 5m 28s\tremaining: 18.4s\n",
      "947:\tlearn: 0.0927679\ttotal: 5m 29s\tremaining: 18.1s\n",
      "948:\tlearn: 0.0927517\ttotal: 5m 29s\tremaining: 17.7s\n",
      "949:\tlearn: 0.0927086\ttotal: 5m 29s\tremaining: 17.4s\n",
      "950:\tlearn: 0.0926927\ttotal: 5m 30s\tremaining: 17s\n",
      "951:\tlearn: 0.0926765\ttotal: 5m 30s\tremaining: 16.7s\n",
      "952:\tlearn: 0.0926401\ttotal: 5m 30s\tremaining: 16.3s\n",
      "953:\tlearn: 0.0926239\ttotal: 5m 31s\tremaining: 16s\n",
      "954:\tlearn: 0.0926082\ttotal: 5m 31s\tremaining: 15.6s\n",
      "955:\tlearn: 0.0925512\ttotal: 5m 31s\tremaining: 15.3s\n",
      "956:\tlearn: 0.0925353\ttotal: 5m 32s\tremaining: 14.9s\n",
      "957:\tlearn: 0.0925191\ttotal: 5m 32s\tremaining: 14.6s\n",
      "958:\tlearn: 0.0924733\ttotal: 5m 32s\tremaining: 14.2s\n",
      "959:\tlearn: 0.0924576\ttotal: 5m 33s\tremaining: 13.9s\n",
      "960:\tlearn: 0.0924420\ttotal: 5m 33s\tremaining: 13.5s\n",
      "961:\tlearn: 0.0924264\ttotal: 5m 34s\tremaining: 13.2s\n",
      "962:\tlearn: 0.0923984\ttotal: 5m 34s\tremaining: 12.8s\n",
      "963:\tlearn: 0.0923826\ttotal: 5m 34s\tremaining: 12.5s\n",
      "964:\tlearn: 0.0923666\ttotal: 5m 35s\tremaining: 12.2s\n",
      "965:\tlearn: 0.0923475\ttotal: 5m 35s\tremaining: 11.8s\n",
      "966:\tlearn: 0.0922687\ttotal: 5m 35s\tremaining: 11.5s\n",
      "967:\tlearn: 0.0922486\ttotal: 5m 36s\tremaining: 11.1s\n",
      "968:\tlearn: 0.0922328\ttotal: 5m 36s\tremaining: 10.8s\n",
      "969:\tlearn: 0.0922172\ttotal: 5m 36s\tremaining: 10.4s\n",
      "970:\tlearn: 0.0922019\ttotal: 5m 37s\tremaining: 10.1s\n",
      "971:\tlearn: 0.0921862\ttotal: 5m 37s\tremaining: 9.72s\n",
      "972:\tlearn: 0.0921558\ttotal: 5m 37s\tremaining: 9.37s\n",
      "973:\tlearn: 0.0921166\ttotal: 5m 38s\tremaining: 9.03s\n",
      "974:\tlearn: 0.0920943\ttotal: 5m 38s\tremaining: 8.68s\n",
      "975:\tlearn: 0.0920792\ttotal: 5m 38s\tremaining: 8.33s\n",
      "976:\tlearn: 0.0920639\ttotal: 5m 39s\tremaining: 7.99s\n",
      "977:\tlearn: 0.0920382\ttotal: 5m 39s\tremaining: 7.64s\n",
      "978:\tlearn: 0.0920226\ttotal: 5m 39s\tremaining: 7.29s\n",
      "979:\tlearn: 0.0920073\ttotal: 5m 40s\tremaining: 6.94s\n",
      "980:\tlearn: 0.0919919\ttotal: 5m 40s\tremaining: 6.6s\n",
      "981:\tlearn: 0.0919759\ttotal: 5m 40s\tremaining: 6.25s\n",
      "982:\tlearn: 0.0919601\ttotal: 5m 41s\tremaining: 5.9s\n",
      "983:\tlearn: 0.0919442\ttotal: 5m 41s\tremaining: 5.55s\n",
      "984:\tlearn: 0.0918954\ttotal: 5m 42s\tremaining: 5.21s\n",
      "985:\tlearn: 0.0918381\ttotal: 5m 42s\tremaining: 4.86s\n",
      "986:\tlearn: 0.0917969\ttotal: 5m 42s\tremaining: 4.51s\n",
      "987:\tlearn: 0.0917778\ttotal: 5m 43s\tremaining: 4.17s\n",
      "988:\tlearn: 0.0917616\ttotal: 5m 43s\tremaining: 3.82s\n",
      "989:\tlearn: 0.0917467\ttotal: 5m 43s\tremaining: 3.47s\n",
      "990:\tlearn: 0.0917318\ttotal: 5m 44s\tremaining: 3.12s\n",
      "991:\tlearn: 0.0917115\ttotal: 5m 44s\tremaining: 2.78s\n",
      "992:\tlearn: 0.0916959\ttotal: 5m 44s\tremaining: 2.43s\n",
      "993:\tlearn: 0.0916801\ttotal: 5m 45s\tremaining: 2.08s\n",
      "994:\tlearn: 0.0916641\ttotal: 5m 45s\tremaining: 1.74s\n",
      "995:\tlearn: 0.0916488\ttotal: 5m 45s\tremaining: 1.39s\n",
      "996:\tlearn: 0.0915856\ttotal: 5m 46s\tremaining: 1.04s\n",
      "997:\tlearn: 0.0915609\ttotal: 5m 46s\tremaining: 694ms\n",
      "998:\tlearn: 0.0915449\ttotal: 5m 46s\tremaining: 347ms\n",
      "999:\tlearn: 0.0915297\ttotal: 5m 47s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7576239340945223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим как себя покажет наш любимый бустинг\n",
    "model_Cat = CatBoostClassifier(iterations=1000,\n",
    "                              learning_rate=0.15)\n",
    "model_Cat.fit(tfidf_train, target_train)\n",
    "predictions_Cat = model_Cat.predict(tfidf_test)\n",
    "\n",
    "\n",
    "f1_score(target_test, predictions_Cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4cf146",
   "metadata": {},
   "source": [
    "**Катбуст дал f1 - 0.75, вроде метрика проходная, но посмотрим что покажет bert**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a70ec",
   "metadata": {},
   "source": [
    "### Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2787c3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1131931993386308"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на балланс классов\n",
    "rat = pd.Series(target).value_counts()[1]/pd.Series(target).value_counts()[0]\n",
    "rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0d92f",
   "metadata": {},
   "source": [
    "Дисбаланс классов налицо, будем устранять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc668927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24353,) (24353,)\n"
     ]
    }
   ],
   "source": [
    "#Напишем функцию по устраниению дисбалланса классов, в нашем случае целесообразнее выполнить downsampling так как Bert модель тяжелая\n",
    "#и много объектов ядро домашней машины просто непотянет и отвалится\n",
    "def downsampling(features, target, fraction):\n",
    "    features_zeros=features[target==0]\n",
    "    features_ones=features[target==1]\n",
    "    target_ones=target[target==1]\n",
    "    target_zeros=target[target==0]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "    [features_zeros.sample(frac=fraction, random_state=12)] + [features_ones])\n",
    "    \n",
    "    target_downsampled = pd.concat(\n",
    "    [target_zeros.sample(frac=fraction, random_state=12)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "    features_downsampled, target_downsampled, random_state=12)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsampling(pd.Series(features_train), pd.Series(target_train), rat)\n",
    "print(features_downsampled.shape, target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb123edb",
   "metadata": {},
   "source": [
    "Готово, вот теперь другое дело."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2167be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возьмем небольшую подвыборку наших данных для модели Bert, таргет берется меньше уже с учётом последующей фильтрации фич по размеру токена\n",
    "features_downsampled = features_downsampled.sample(800)\n",
    "target_downsampled = target_downsampled.sample(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1013d780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Токенизируем данные и проверим размер получившихся векторов\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "tokenized = features_downsampled.apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b1474e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Приведем все вектора к одному размеру путем добавления нулей \n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6701f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создадим маску внимания, чтобы модель обращала внимание на ненулевые токены в векторе \n",
    "attention_mask = np.where(padded !=0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e61569f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829c8973a5f0404ea62b5adeb82d375d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.09659109,  0.006181  , -0.00133071, ..., -0.10542802,\n",
       "          0.3846906 ,  0.4091116 ],\n",
       "        [ 0.32216868,  0.2822963 , -0.23127265, ..., -0.26801816,\n",
       "          0.5261541 ,  0.05518529],\n",
       "        [ 0.07144033,  0.04216814,  0.00959358, ..., -0.16574593,\n",
       "         -0.03998029,  0.2828487 ],\n",
       "        ...,\n",
       "        [ 0.07031427,  0.05913085,  0.1047712 , ..., -0.10739137,\n",
       "          0.5102302 ,  0.4495869 ],\n",
       "        [-0.16052523,  0.02816637, -0.20893736, ..., -0.21196859,\n",
       "          0.25574112,  0.41466814],\n",
       "        [-0.04135018, -0.05734237,  0.0627276 , ..., -0.08693473,\n",
       "          0.38504317,  0.3606385 ]], dtype=float32),\n",
       " array([[-0.38522106, -0.1355881 , -0.13347562, ..., -0.13157031,\n",
       "          0.53072244,  0.4376408 ],\n",
       "        [ 0.09495325,  0.28211328, -0.07077929, ...,  0.04767526,\n",
       "          0.30706087,  0.23943298],\n",
       "        [ 0.23659882, -0.00561754,  0.08020873, ..., -0.33377242,\n",
       "          0.40538228,  0.15144567],\n",
       "        ...,\n",
       "        [ 0.21688077,  0.1175843 , -0.01667043, ..., -0.21106192,\n",
       "          0.54487395,  0.12847358],\n",
       "        [-0.19063656, -0.05864867, -0.00599885, ...,  0.06331983,\n",
       "          0.5718762 ,  0.32135248],\n",
       "        [ 0.21056867,  0.02916013,  0.09382949, ..., -0.04360573,\n",
       "          0.29301393,  0.3363534 ]], dtype=float32),\n",
       " array([[-0.16362144, -0.11465397, -0.08541   , ..., -0.36091682,\n",
       "          0.6505267 , -0.04440662],\n",
       "        [ 0.15814523,  0.13942339, -0.12391698, ..., -0.05723088,\n",
       "          0.38539737,  0.39587176],\n",
       "        [ 0.1316275 ,  0.34788197, -0.07933292, ..., -0.15261261,\n",
       "          0.5336379 ,  0.52021253],\n",
       "        ...,\n",
       "        [ 0.18565607, -0.03726061, -0.01765698, ..., -0.04149187,\n",
       "          0.28758508,  0.21135719],\n",
       "        [ 0.07918034,  0.13629569,  0.21728541, ..., -0.23219593,\n",
       "          0.43053716,  0.01878645],\n",
       "        [ 0.0460079 ,  0.04178359,  0.00854605, ..., -0.15236112,\n",
       "          0.61332005,  0.17452393]], dtype=float32),\n",
       " array([[ 0.08250915,  0.09718526, -0.09560326, ..., -0.22167751,\n",
       "          0.33672082,  0.07754999],\n",
       "        [-0.19892885,  0.0828871 , -0.11193323, ..., -0.07847062,\n",
       "          0.30293915,  0.22533548],\n",
       "        [-0.22620037,  0.09144794, -0.09312709, ..., -0.14018284,\n",
       "          0.49766842, -0.009652  ],\n",
       "        ...,\n",
       "        [ 0.10164015, -0.07464764,  0.0173219 , ..., -0.16715956,\n",
       "          0.35842645,  0.31173074],\n",
       "        [-0.05552471,  0.02750386, -0.05168007, ..., -0.09691954,\n",
       "          0.28210592,  0.29220966],\n",
       "        [ 0.11387146, -0.03296482,  0.23215394, ..., -0.19327378,\n",
       "          0.3283709 ,  0.11517741]], dtype=float32),\n",
       " array([[ 0.25811678,  0.08283085, -0.03752141, ..., -0.03923063,\n",
       "          0.39264134,  0.4047531 ],\n",
       "        [-0.03731747, -0.02271889,  0.04681106, ..., -0.09101706,\n",
       "          0.29016635,  0.24171285],\n",
       "        [-0.03866532, -0.11142187, -0.00789295, ..., -0.24877554,\n",
       "          0.4051474 ,  0.27835652],\n",
       "        ...,\n",
       "        [ 0.00897503,  0.00123348, -0.03229238, ..., -0.17853184,\n",
       "          0.27637905,  0.25292224],\n",
       "        [ 0.06790854, -0.05251685,  0.05668095, ..., -0.12274741,\n",
       "          0.5716286 ,  0.31558812],\n",
       "        [ 0.00476701,  0.08351526, -0.08382438, ..., -0.03590613,\n",
       "          0.5686578 ,  0.32970145]], dtype=float32),\n",
       " array([[ 0.02974108,  0.05519111, -0.08768326, ..., -0.09549809,\n",
       "          0.3734496 ,  0.37912327],\n",
       "        [-0.22306277,  0.10826228,  0.21095431, ..., -0.01957445,\n",
       "          0.1956447 ,  0.40758923],\n",
       "        [-0.00642452, -0.08707066,  0.06402717, ..., -0.03738506,\n",
       "          0.18432382,  0.31082496],\n",
       "        ...,\n",
       "        [ 0.06798543,  0.04163642,  0.03039383, ..., -0.17119452,\n",
       "          0.44429663,  0.16168247],\n",
       "        [ 0.03902574, -0.10213254,  0.13636115, ..., -0.0857641 ,\n",
       "          0.36799592,  0.27680066],\n",
       "        [ 0.07576085, -0.20622593,  0.25185966, ...,  0.103556  ,\n",
       "          0.02815709,  0.8153707 ]], dtype=float32),\n",
       " array([[ 0.21335974, -0.04475666,  0.06666442, ..., -0.14091384,\n",
       "          0.5392283 ,  0.20589396],\n",
       "        [ 0.14975555, -0.01642218, -0.10478212, ..., -0.31825286,\n",
       "          0.448117  ,  0.09280936],\n",
       "        [-0.11333986,  0.14227702,  0.11972059, ..., -0.2307037 ,\n",
       "          0.2697822 ,  0.37406063],\n",
       "        ...,\n",
       "        [ 0.2532283 ,  0.01247448, -0.01924438, ...,  0.17719096,\n",
       "          0.15039599, -0.16302113],\n",
       "        [-0.12487398,  0.06047039,  0.0526314 , ..., -0.11066337,\n",
       "          0.3247445 ,  0.27842465],\n",
       "        [ 0.18308574,  0.20867327,  0.05163803, ...,  0.0299761 ,\n",
       "          0.38554117,  0.182071  ]], dtype=float32),\n",
       " array([[ 0.25566125,  0.3738541 , -0.29824615, ..., -0.13733855,\n",
       "          0.48675042,  0.27513704],\n",
       "        [-0.21578345,  0.208306  ,  0.0935818 , ..., -0.20606576,\n",
       "          0.21693313,  0.52218115],\n",
       "        [ 0.19542383,  0.16698109, -0.02956933, ..., -0.08460861,\n",
       "          0.484076  ,  0.16242732],\n",
       "        ...,\n",
       "        [ 0.11020724,  0.0612641 ,  0.07273683, ...,  0.05811748,\n",
       "          0.30823416,  0.20363827],\n",
       "        [ 0.16926764,  0.06087149, -0.06973343, ..., -0.10640687,\n",
       "          0.4425931 ,  0.25227734],\n",
       "        [-0.03774888,  0.18561994, -0.02094087, ..., -0.05247951,\n",
       "          0.49671617,  0.18229973]], dtype=float32),\n",
       " array([[ 0.22512251,  0.11367912,  0.15832934, ..., -0.18082993,\n",
       "          0.5419717 ,  0.26520583],\n",
       "        [-0.30490518, -0.0146769 , -0.0452026 , ...,  0.03591435,\n",
       "          0.43356588,  0.24532734],\n",
       "        [ 0.05700445, -0.0240104 , -0.14054848, ..., -0.19909355,\n",
       "          0.529188  ,  0.36839062],\n",
       "        ...,\n",
       "        [ 0.01347901,  0.15109067,  0.18247452, ..., -0.09891555,\n",
       "          0.42718655,  0.3594462 ],\n",
       "        [ 0.25360245,  0.1957018 ,  0.00254069, ..., -0.10609823,\n",
       "          0.55921745,  0.05413307],\n",
       "        [ 0.03268218,  0.03306915, -0.01098879, ..., -0.11223584,\n",
       "          0.40334034,  0.3785488 ]], dtype=float32),\n",
       " array([[ 0.00837523, -0.08671835, -0.29420173, ...,  0.09086396,\n",
       "          0.27118596,  0.35053945],\n",
       "        [ 0.18160623,  0.17070644,  0.14444876, ..., -0.19945653,\n",
       "          0.579977  ,  0.26124504],\n",
       "        [ 0.22961327,  0.05170043, -0.13897082, ..., -0.19297138,\n",
       "          0.6134254 ,  0.3013028 ],\n",
       "        ...,\n",
       "        [-0.01855817,  0.13576686,  0.03440841, ..., -0.10284926,\n",
       "          0.41329437,  0.35277146],\n",
       "        [ 0.09673324,  0.23238188,  0.09006963, ..., -0.05250072,\n",
       "          0.41017818,  0.17751169],\n",
       "        [ 0.12394111,  0.38876244,  0.01636371, ..., -0.09546829,\n",
       "          0.30363503,  0.28126693]], dtype=float32),\n",
       " array([[-0.10594209,  0.23341128,  0.03495545, ..., -0.16640535,\n",
       "          0.32492378,  0.28084666],\n",
       "        [-0.19068052, -0.09017471, -0.48697984, ...,  0.03678345,\n",
       "          0.68189955,  0.1902832 ],\n",
       "        [ 0.04739272,  0.11059525, -0.05064543, ..., -0.14911719,\n",
       "          0.2754883 ,  0.16211088],\n",
       "        ...,\n",
       "        [ 0.14571117,  0.19038397,  0.0172607 , ..., -0.1561806 ,\n",
       "          0.38628063,  0.15107521],\n",
       "        [ 0.27102768, -0.11024151,  0.07209314, ..., -0.36994177,\n",
       "          0.49620292,  0.07704972],\n",
       "        [-0.08147056, -0.11655553,  0.2325718 , ..., -0.28541836,\n",
       "          0.41480154, -0.05747063]], dtype=float32),\n",
       " array([[ 0.26294002,  0.3049797 , -0.15704498, ..., -0.4229066 ,\n",
       "          0.58976936,  0.1352159 ],\n",
       "        [ 0.25824493,  0.06519141, -0.08311592, ..., -0.32534066,\n",
       "          0.6137936 ,  0.25104374],\n",
       "        [ 0.24755043,  0.17665988, -0.23283966, ..., -0.01284599,\n",
       "          0.5587027 ,  0.37185916],\n",
       "        ...,\n",
       "        [-0.01138796,  0.08078427,  0.28412038, ..., -0.49378744,\n",
       "          0.43783817,  0.41530275],\n",
       "        [-0.00313173,  0.03905632,  0.11342067, ..., -0.01557965,\n",
       "          0.26719904,  0.25171542],\n",
       "        [ 0.0973677 ,  0.12775686,  0.21852008, ..., -0.21212706,\n",
       "          0.22288539,  0.23375185]], dtype=float32),\n",
       " array([[-0.02974373,  0.0152022 ,  0.0904813 , ..., -0.13758367,\n",
       "          0.20557864,  0.1342282 ],\n",
       "        [ 0.16229624,  0.2742392 , -0.21362557, ...,  0.17466746,\n",
       "          0.44360632,  0.41584644],\n",
       "        [-0.13719761,  0.20019837, -0.11694391, ..., -0.00891981,\n",
       "          0.45480913,  0.30825868],\n",
       "        ...,\n",
       "        [ 0.09575894,  0.19385603,  0.0364111 , ..., -0.2694887 ,\n",
       "          0.40860924,  0.09627493],\n",
       "        [-0.02833533,  0.18861412,  0.02707318, ..., -0.22586277,\n",
       "          0.2833577 ,  0.239     ],\n",
       "        [ 0.00252614,  0.07619767,  0.02696973, ..., -0.08042384,\n",
       "          0.57346785,  0.23220181]], dtype=float32),\n",
       " array([[ 0.15588222,  0.09007049, -0.12462068, ..., -0.07832639,\n",
       "          0.44663948,  0.40026727],\n",
       "        [ 0.08659475,  0.17606786, -0.07421069, ..., -0.07507365,\n",
       "          0.36560282,  0.06957996],\n",
       "        [ 0.31042454,  0.3584087 , -0.24181093, ..., -0.36964962,\n",
       "          0.8354752 ,  0.24302728],\n",
       "        ...,\n",
       "        [-0.0349457 ,  0.05026796,  0.08923403, ..., -0.2198493 ,\n",
       "          0.24553628,  0.24070527],\n",
       "        [-0.066201  ,  0.15291494, -0.00402105, ..., -0.24188899,\n",
       "          0.664104  ,  0.43048593],\n",
       "        [ 0.02882905,  0.23429848,  0.03174372, ..., -0.03372343,\n",
       "          0.34516168,  0.24549825]], dtype=float32),\n",
       " array([[-0.01508265, -0.05378161,  0.13594547, ..., -0.19173023,\n",
       "          0.355477  ,  0.2598677 ],\n",
       "        [-0.02077521,  0.19147031,  0.01152474, ...,  0.02456049,\n",
       "          0.2710734 ,  0.31078756],\n",
       "        [-0.3469575 ,  0.05396433, -0.19116704, ..., -0.10332628,\n",
       "          0.20036598,  0.23182067],\n",
       "        ...,\n",
       "        [ 0.01003689,  0.05595963,  0.0150895 , ..., -0.04909967,\n",
       "          0.29285058,  0.2787356 ],\n",
       "        [ 0.03215173, -0.06066972,  0.02878087, ..., -0.0498853 ,\n",
       "          0.29757047,  0.34520942],\n",
       "        [ 0.00274763, -0.13577242, -0.09573625, ..., -0.04240613,\n",
       "          0.3755026 ,  0.10447343]], dtype=float32),\n",
       " array([[ 0.08886799,  0.04154199, -0.01681757, ..., -0.09311296,\n",
       "          0.4342955 ,  0.3414854 ],\n",
       "        [-0.03203888,  0.17130016,  0.01716509, ...,  0.01291595,\n",
       "          0.44527256,  0.45479432],\n",
       "        [ 0.20598081,  0.19947217, -0.02497201, ..., -0.16218351,\n",
       "          0.649117  ,  0.07473069],\n",
       "        ...,\n",
       "        [ 0.20475772,  0.16553621,  0.08531613, ...,  0.01079609,\n",
       "          0.28691217,  0.6407674 ],\n",
       "        [ 0.31595206, -0.00205893,  0.00413457, ...,  0.005287  ,\n",
       "          0.45587003,  0.3797259 ],\n",
       "        [-0.14653558, -0.23421128,  0.14231643, ...,  0.01747561,\n",
       "          0.25289398,  0.44741735]], dtype=float32),\n",
       " array([[ 0.30915368,  0.2073957 ,  0.16314246, ..., -0.27186954,\n",
       "          0.2600764 ,  0.15198684],\n",
       "        [ 0.04566585,  0.18821263,  0.09314123, ..., -0.11330272,\n",
       "          0.29347196,  0.35991445],\n",
       "        [-0.02815021, -0.05633708,  0.16490617, ..., -0.24239008,\n",
       "          0.28858444,  0.29234922],\n",
       "        ...,\n",
       "        [ 0.27955964,  0.24659176, -0.07451986, ..., -0.13753109,\n",
       "          0.5685018 ,  0.05561323],\n",
       "        [ 0.18796298,  0.02855882,  0.09977965, ..., -0.3146658 ,\n",
       "          0.4257855 ,  0.34963685],\n",
       "        [ 0.2241188 ,  0.03919432, -0.02759668, ..., -0.1083027 ,\n",
       "          0.43687403,  0.19573359]], dtype=float32),\n",
       " array([[-0.06848973, -0.22830693,  0.19684102, ..., -0.08165705,\n",
       "          0.34054473,  0.41381854],\n",
       "        [ 0.00231267,  0.13937205, -0.17839466, ..., -0.12069809,\n",
       "          0.61114496,  0.2341996 ],\n",
       "        [ 0.09549493,  0.02987274, -0.07729173, ..., -0.3578546 ,\n",
       "          0.69542205,  0.11510827],\n",
       "        ...,\n",
       "        [-0.01035523,  0.18473478, -0.26677954, ..., -0.16585992,\n",
       "          0.48663598,  0.04103491],\n",
       "        [-0.19135173,  0.10027906,  0.03984124, ...,  0.04453937,\n",
       "          0.36380395,  0.4308298 ],\n",
       "        [-0.09256023,  0.05610354, -0.12032999, ..., -0.14883938,\n",
       "          0.3629084 ,  0.2534819 ]], dtype=float32),\n",
       " array([[-0.19732858, -0.14216949,  0.12125541, ..., -0.12069504,\n",
       "          0.07660855,  0.5175429 ],\n",
       "        [ 0.11058234,  0.03032281,  0.12227277, ..., -0.091333  ,\n",
       "          0.4947728 ,  0.18211114],\n",
       "        [-0.05296244,  0.02346214,  0.00610953, ..., -0.08431142,\n",
       "          0.33763757,  0.3242106 ],\n",
       "        ...,\n",
       "        [ 0.05654984,  0.00776609,  0.27207306, ..., -0.18597463,\n",
       "          0.38387892,  0.14384016],\n",
       "        [ 0.1477517 ,  0.16970813, -0.00881552, ..., -0.037731  ,\n",
       "          0.69967926,  0.04948786],\n",
       "        [-0.03450267,  0.03248025,  0.02077686, ..., -0.1676866 ,\n",
       "          0.42333835,  0.08079132]], dtype=float32),\n",
       " array([[ 0.15770371, -0.11801679, -0.01816568, ..., -0.06130569,\n",
       "          0.46980613,  0.01221302],\n",
       "        [ 0.04493074, -0.05585108, -0.02215539, ..., -0.07569796,\n",
       "          0.36447155,  0.29228112],\n",
       "        [ 0.27372372,  0.14841352, -0.23706804, ..., -0.36854008,\n",
       "          0.4450255 ,  0.11625776],\n",
       "        ...,\n",
       "        [-0.08813262,  0.10017646,  0.14215463, ..., -0.17768367,\n",
       "          0.27361533,  0.26845494],\n",
       "        [-0.00167886,  0.12014718,  0.17289925, ..., -0.18625025,\n",
       "          0.4455867 ,  0.24783535],\n",
       "        [-0.04209316, -0.06671581,  0.3116141 , ..., -0.09382883,\n",
       "          0.13661568,  0.2955754 ]], dtype=float32),\n",
       " array([[-0.105827  , -0.19179851, -0.10699733, ..., -0.12119173,\n",
       "          0.2999556 ,  0.39098555],\n",
       "        [ 0.14692086,  0.28418022,  0.01120497, ..., -0.35361564,\n",
       "          0.36150774,  0.04735056],\n",
       "        [ 0.3570053 ,  0.12329095,  0.1410751 , ..., -0.10470714,\n",
       "          0.6173663 ,  0.14823933],\n",
       "        ...,\n",
       "        [-0.03719819,  0.11289322, -0.2088084 , ..., -0.17566377,\n",
       "          0.5129504 ,  0.28482744],\n",
       "        [ 0.10516483, -0.05030105, -0.0079515 , ..., -0.10693569,\n",
       "          0.71335953,  0.25401816],\n",
       "        [-0.09998797,  0.1376235 ,  0.06435286, ..., -0.10764388,\n",
       "          0.45073786,  0.17790717]], dtype=float32),\n",
       " array([[ 0.02176598,  0.0975497 , -0.1628716 , ..., -0.045224  ,\n",
       "          0.39089763,  0.30720288],\n",
       "        [ 0.18744853, -0.08522207,  0.0232288 , ..., -0.09936783,\n",
       "          0.49676168,  0.14211608],\n",
       "        [ 0.09740721,  0.3022255 , -0.05766484, ..., -0.17917421,\n",
       "          0.4902115 ,  0.15680885],\n",
       "        ...,\n",
       "        [-0.27083   ,  0.02322719, -0.00973733, ..., -0.0932391 ,\n",
       "          0.2998133 ,  0.16043347],\n",
       "        [ 0.05723616,  0.04564068,  0.06532274, ..., -0.11217691,\n",
       "          0.5500874 ,  0.07705668],\n",
       "        [ 0.01112481,  0.13447824, -0.13354439, ..., -0.03444685,\n",
       "          0.27420348,  0.30207777]], dtype=float32),\n",
       " array([[-0.03300421,  0.08801967, -0.18246038, ..., -0.03152217,\n",
       "          0.41895965,  0.44393376],\n",
       "        [ 0.09232081,  0.00687953, -0.17675716, ..., -0.30353394,\n",
       "          0.5491109 ,  0.02112374],\n",
       "        [-0.10251896, -0.01648489,  0.11472835, ..., -0.27658853,\n",
       "          0.2845679 ,  0.21929887],\n",
       "        ...,\n",
       "        [ 0.06299455,  0.07993421,  0.04611231, ..., -0.16813819,\n",
       "          0.55817103,  0.23718005],\n",
       "        [-0.06407565, -0.15537289,  0.10347917, ..., -0.20014292,\n",
       "          0.35662562,  0.4098673 ],\n",
       "        [ 0.10159875,  0.13832577,  0.10149163, ..., -0.23946372,\n",
       "          0.265205  ,  0.06384241]], dtype=float32),\n",
       " array([[ 0.22231337,  0.20170364,  0.05926808, ..., -0.02810181,\n",
       "          0.33611587,  0.3133693 ],\n",
       "        [ 0.14832199,  0.11175155,  0.08001746, ..., -0.18376666,\n",
       "          0.3756199 ,  0.17220765],\n",
       "        [ 0.05413489, -0.12059034, -0.17047305, ..., -0.10660694,\n",
       "          0.4153962 ,  0.31306118],\n",
       "        ...,\n",
       "        [ 0.08454646,  0.01090482, -0.10748138, ..., -0.00170586,\n",
       "          0.56881887,  0.24583681],\n",
       "        [ 0.08779229,  0.05519556, -0.04325258, ..., -0.1358247 ,\n",
       "          0.3958126 ,  0.23910923],\n",
       "        [ 0.10382181,  0.26253518,  0.01201586, ..., -0.1862722 ,\n",
       "          0.5152657 ,  0.28809   ]], dtype=float32),\n",
       " array([[-0.16894001, -0.03704783,  0.05241372, ..., -0.07024771,\n",
       "          0.52006996,  0.13515435],\n",
       "        [-0.20317525,  0.02249704, -0.0559303 , ..., -0.16569099,\n",
       "          0.41524315,  0.43046   ],\n",
       "        [-0.08443297,  0.07691087,  0.09213875, ..., -0.21536884,\n",
       "          0.33425865,  0.17279065],\n",
       "        ...,\n",
       "        [ 0.08188787, -0.05971847,  0.06534906, ..., -0.1457642 ,\n",
       "          0.44439024,  0.09027179],\n",
       "        [-0.1527221 , -0.11727976,  0.32533735, ..., -0.20123224,\n",
       "          0.45169708,  0.36712268],\n",
       "        [ 0.03555465,  0.12252841, -0.0209341 , ..., -0.06656993,\n",
       "          0.4048263 ,  0.21453688]], dtype=float32),\n",
       " array([[ 1.1978030e-02,  1.8575414e-01,  1.6694894e-01, ...,\n",
       "         -1.5765235e-01,  3.1474462e-01,  1.6562729e-01],\n",
       "        [ 2.1325728e-01, -3.7039317e-02, -1.6450882e-04, ...,\n",
       "          3.1142861e-02,  2.4908614e-01,  5.5547321e-01],\n",
       "        [-2.0161384e-01,  1.6594639e-01, -1.7335027e-01, ...,\n",
       "         -6.0628001e-02,  2.6403832e-01,  4.3004403e-01],\n",
       "        ...,\n",
       "        [-2.5278145e-01,  2.9415190e-01, -4.8552535e-02, ...,\n",
       "         -2.0240600e-01,  5.5650926e-01,  3.7921140e-01],\n",
       "        [ 7.7290267e-02,  7.2507299e-02, -9.4548002e-02, ...,\n",
       "         -3.8527811e-01,  5.9094310e-01,  3.3472411e-02],\n",
       "        [ 4.3192975e-02,  6.3249081e-02, -1.8013449e-01, ...,\n",
       "         -1.1462560e-01,  4.6150947e-01,  1.9389543e-01]], dtype=float32),\n",
       " array([[-0.00846272,  0.02543237, -0.41773152, ..., -0.15392363,\n",
       "          0.36032873,  0.0521999 ],\n",
       "        [ 0.05901007,  0.13753624,  0.12725665, ..., -0.07702665,\n",
       "          0.4363608 ,  0.1756943 ],\n",
       "        [ 0.15195444,  0.05321136, -0.28568572, ..., -0.40496156,\n",
       "          0.3461761 , -0.09080108],\n",
       "        ...,\n",
       "        [ 0.04566538, -0.2972072 , -0.24067985, ..., -0.15207195,\n",
       "          0.3605772 ,  0.19480576],\n",
       "        [ 0.34794828,  0.12516321, -0.0253194 , ..., -0.12905358,\n",
       "          0.53371453,  0.06906731],\n",
       "        [ 0.11419006,  0.05368728, -0.09963465, ..., -0.1507074 ,\n",
       "          0.5577094 ,  0.26834977]], dtype=float32),\n",
       " array([[-0.25606102,  0.03872009,  0.02984943, ..., -0.00465068,\n",
       "          0.43347457,  0.22080524],\n",
       "        [ 0.02332411, -0.04322146, -0.00275036, ..., -0.21426459,\n",
       "          0.24673203,  0.38491866],\n",
       "        [ 0.13032275,  0.18276726,  0.07794483, ..., -0.2624201 ,\n",
       "          0.6163952 ,  0.19880699],\n",
       "        ...,\n",
       "        [ 0.19355957,  0.42372477, -0.09009023, ..., -0.34088475,\n",
       "          0.47180647,  0.28629118],\n",
       "        [ 0.10573338, -0.04600139, -0.01935638, ..., -0.11484324,\n",
       "          0.47232506,  0.07894906],\n",
       "        [ 0.12085144,  0.25480318,  0.08707634, ..., -0.1935352 ,\n",
       "          0.37417853,  0.4354925 ]], dtype=float32),\n",
       " array([[-0.20187846, -0.17561373,  0.17422196, ..., -0.27991396,\n",
       "          0.69911504,  0.09319804],\n",
       "        [-0.2192754 , -0.03986036,  0.06783761, ..., -0.1967346 ,\n",
       "          0.31415814,  0.2864589 ],\n",
       "        [-0.12312114, -0.00254255,  0.07874139, ..., -0.0605964 ,\n",
       "          0.11263094,  0.27981165],\n",
       "        ...,\n",
       "        [-0.0355848 ,  0.06452971, -0.04529401, ..., -0.15779226,\n",
       "          0.26692542,  0.41637376],\n",
       "        [-0.12691431,  0.23618744, -0.05793729, ..., -0.01148151,\n",
       "          0.29554254,  0.24764644],\n",
       "        [ 0.06539306, -0.11825759, -0.12339243, ..., -0.09084655,\n",
       "          0.6553726 ,  0.18212306]], dtype=float32),\n",
       " array([[-0.23245546,  0.09372896, -0.02114661, ..., -0.25901437,\n",
       "          0.42187446,  0.33119178],\n",
       "        [ 0.20924318,  0.14564027, -0.03632308, ..., -0.02235697,\n",
       "          0.43998876,  0.24724837],\n",
       "        [ 0.0311547 ,  0.39064667, -0.00766366, ..., -0.6712505 ,\n",
       "          0.5491853 , -0.02079945],\n",
       "        ...,\n",
       "        [-0.1667982 , -0.07523952, -0.03291443, ..., -0.37139896,\n",
       "          0.65244526,  0.18387064],\n",
       "        [-0.07438984, -0.07607669,  0.01048617, ..., -0.09902723,\n",
       "          0.6608939 ,  0.20777296],\n",
       "        [ 0.08477296,  0.1403429 ,  0.09539845, ..., -0.21404341,\n",
       "          0.36650673,  0.28198045]], dtype=float32),\n",
       " array([[-0.20896326, -0.02764035,  0.02151243, ..., -0.11961885,\n",
       "          0.18760823,  0.31019056],\n",
       "        [ 0.08373909,  0.22435541, -0.09685725, ..., -0.19343595,\n",
       "          0.61067545,  0.3387003 ],\n",
       "        [-0.00504398,  0.00953395,  0.18418095, ..., -0.11573253,\n",
       "          0.4903124 ,  0.25489843],\n",
       "        ...,\n",
       "        [-0.08520687,  0.03640036, -0.16329898, ..., -0.03951849,\n",
       "          0.08956439,  0.23380625],\n",
       "        [ 0.1333891 ,  0.19167364,  0.01987116, ..., -0.15568331,\n",
       "          0.52538466,  0.35280427],\n",
       "        [ 0.21664882,  0.15347356,  0.26646876, ..., -0.24366997,\n",
       "          0.81677496,  0.08277609]], dtype=float32),\n",
       " array([[ 0.09690507, -0.00683759,  0.14380755, ...,  0.06422301,\n",
       "          0.41236565,  0.190924  ],\n",
       "        [ 0.23500785,  0.05656336,  0.03771682, ..., -0.21641259,\n",
       "          0.5751008 ,  0.30133283],\n",
       "        [-0.08375989, -0.0743477 , -0.2768656 , ..., -0.04425181,\n",
       "          0.37426522,  0.5020215 ],\n",
       "        ...,\n",
       "        [-0.16818944, -0.14801133,  0.01880855, ..., -0.2513407 ,\n",
       "          0.21933688,  0.297051  ],\n",
       "        [ 0.0569558 ,  0.12643702, -0.02512237, ..., -0.09782036,\n",
       "          0.3428851 ,  0.14742397],\n",
       "        [ 0.14764054,  0.18235624,  0.11311737, ..., -0.18061444,\n",
       "          0.32336766,  0.11445431]], dtype=float32),\n",
       " array([[ 2.17925668e-01,  2.07786143e-01, -1.23737141e-01, ...,\n",
       "         -1.72704265e-01,  5.76495826e-01,  3.39086860e-01],\n",
       "        [ 1.17223412e-01,  3.76755774e-01,  1.15828507e-01, ...,\n",
       "         -1.12225980e-01,  5.99716961e-01,  4.68009472e-01],\n",
       "        [ 8.39675516e-02, -7.80348107e-02,  9.72003192e-02, ...,\n",
       "         -3.29379737e-01,  6.49653256e-01,  5.40307015e-02],\n",
       "        ...,\n",
       "        [ 1.27853736e-01,  1.04858793e-01,  2.31426992e-02, ...,\n",
       "         -2.20619574e-01,  4.49125022e-01,  3.51859331e-01],\n",
       "        [ 1.03248119e-01, -4.56245616e-03,  1.72328390e-02, ...,\n",
       "         -1.08132586e-01,  4.58924681e-01,  3.73079330e-01],\n",
       "        [-5.86934537e-02, -6.08457252e-04,  5.98686747e-02, ...,\n",
       "         -3.15942794e-01,  2.81969637e-01,  1.55328080e-01]], dtype=float32),\n",
       " array([[-0.3375258 , -0.25333762, -0.14247967, ..., -0.13091405,\n",
       "          0.31910425,  0.2353151 ],\n",
       "        [-0.08234853, -0.12379237, -0.2755869 , ..., -0.03474325,\n",
       "          0.6340001 ,  0.49202853],\n",
       "        [ 0.1819691 ,  0.14609627, -0.05005512, ..., -0.17335808,\n",
       "          0.51159996,  0.18302211],\n",
       "        ...,\n",
       "        [ 0.05143478,  0.00269165,  0.46625662, ..., -0.19148962,\n",
       "          0.6240565 ,  0.45125666],\n",
       "        [-0.1094157 ,  0.21610701, -0.10046428, ..., -0.29189864,\n",
       "          0.6068111 ,  0.3557633 ],\n",
       "        [ 0.06811474,  0.00861434,  0.00651813, ..., -0.15048495,\n",
       "          0.5058201 ,  0.31124142]], dtype=float32),\n",
       " array([[ 0.17175655,  0.05269194, -0.2074383 , ..., -0.07121944,\n",
       "          0.41201103,  0.32543156],\n",
       "        [-0.0193564 ,  0.00169498,  0.09051025, ..., -0.02775066,\n",
       "          0.37279573,  0.2437865 ],\n",
       "        [-0.11762445,  0.02762306, -0.03385331, ..., -0.03849449,\n",
       "          0.29340234,  0.3016602 ],\n",
       "        ...,\n",
       "        [-0.37641317, -0.06811244, -0.05891345, ..., -0.08425476,\n",
       "          0.33846492,  0.395491  ],\n",
       "        [-0.18904242, -0.02761623,  0.22603011, ..., -0.26622513,\n",
       "          0.4876465 ,  0.32340688],\n",
       "        [ 0.11729509,  0.09545852,  0.15639216, ..., -0.24365237,\n",
       "          0.23754843,  0.20749104]], dtype=float32),\n",
       " array([[-0.3287043 ,  0.5500115 ,  0.09065678, ...,  0.05680754,\n",
       "          0.50659156,  0.43147624],\n",
       "        [ 0.06218992,  0.00845176,  0.05614547, ..., -0.01274504,\n",
       "          0.3163031 ,  0.24949785],\n",
       "        [-0.13558301, -0.10260393, -0.06832218, ...,  0.10687888,\n",
       "          0.18789147,  0.5159858 ],\n",
       "        ...,\n",
       "        [ 0.05250872,  0.14454477,  0.27644408, ..., -0.21794496,\n",
       "          0.2679159 ,  0.0893943 ],\n",
       "        [-0.07618977, -0.1387018 , -0.15134405, ..., -0.1971898 ,\n",
       "          0.2156544 ,  0.7222692 ],\n",
       "        [ 0.2570904 , -0.1702457 ,  0.09106626, ..., -0.26312196,\n",
       "          0.58550304, -0.05901678]], dtype=float32),\n",
       " array([[ 0.1759809 ,  0.2566606 , -0.31415045, ...,  0.02125089,\n",
       "          0.6046773 ,  0.12118797],\n",
       "        [ 0.03689587,  0.0372249 , -0.06334567, ..., -0.04473658,\n",
       "          0.2404429 ,  0.22132942],\n",
       "        [-0.07002471, -0.14752658,  0.1549596 , ..., -0.18420663,\n",
       "          0.2995255 ,  0.40312237],\n",
       "        ...,\n",
       "        [ 0.09689167, -0.09263127,  0.2538987 , ..., -0.01307991,\n",
       "          0.43741792, -0.11092939],\n",
       "        [ 0.08638754,  0.10137662,  0.06570984, ...,  0.04388658,\n",
       "          0.4581838 , -0.20069301],\n",
       "        [ 0.05612224,  0.02131656, -0.1310221 , ..., -0.341431  ,\n",
       "          0.55009836,  0.1806934 ]], dtype=float32),\n",
       " array([[ 0.20271014,  0.2785899 ,  0.05433036, ..., -0.14703806,\n",
       "          0.5324264 , -0.01234316],\n",
       "        [ 0.36737862,  0.18020323, -0.21554728, ...,  0.01883717,\n",
       "          0.6620547 ,  0.15827936],\n",
       "        [-0.30160335, -0.12069203, -0.05960231, ..., -0.21634163,\n",
       "          0.2461521 ,  0.45473891],\n",
       "        ...,\n",
       "        [-0.09602648, -0.07456608, -0.04918031, ..., -0.19753422,\n",
       "          0.3751486 ,  0.35843465],\n",
       "        [ 0.10324866,  0.02059914, -0.1710936 , ..., -0.3897511 ,\n",
       "          0.43433964,  0.3245201 ],\n",
       "        [-0.05799076,  0.06549805, -0.0853388 , ..., -0.2167188 ,\n",
       "          0.7211814 ,  0.02589101]], dtype=float32),\n",
       " array([[ 0.05192904,  0.08691449, -0.08847   , ...,  0.00899353,\n",
       "          0.2551781 ,  0.33547792],\n",
       "        [-0.00609829,  0.16079383,  0.04081985, ..., -0.08982726,\n",
       "          0.39853448,  0.20956181],\n",
       "        [-0.12102068,  0.02592892,  0.02793601, ..., -0.2579802 ,\n",
       "          0.2953035 ,  0.29626134],\n",
       "        ...,\n",
       "        [ 0.05518448,  0.14350645, -0.08454105, ..., -0.05392124,\n",
       "          0.5236852 ,  0.14846563],\n",
       "        [-0.20255017,  0.0371128 , -0.0755606 , ..., -0.09419721,\n",
       "          0.5704166 ,  0.42177218],\n",
       "        [ 0.18457511,  0.21384738,  0.05975733, ..., -0.0976386 ,\n",
       "          0.49752808,  0.3584123 ]], dtype=float32),\n",
       " array([[-0.02722026,  0.14014557,  0.00185452, ..., -0.28919265,\n",
       "          0.39901876,  0.17857732],\n",
       "        [ 0.27367386,  0.10585358,  0.19405317, ..., -0.13335899,\n",
       "          0.48270592,  0.01954967],\n",
       "        [-0.03129829,  0.00393639, -0.07635902, ..., -0.23608494,\n",
       "          0.36537057, -0.1958126 ],\n",
       "        ...,\n",
       "        [ 0.08652821,  0.19145171, -0.28422022, ..., -0.23379485,\n",
       "          0.45085967,  0.04937818],\n",
       "        [-0.19975331,  0.16538621,  0.10905918, ..., -0.03636931,\n",
       "          0.5848566 ,  0.1562495 ],\n",
       "        [-0.42848262,  0.0523655 ,  0.12669893, ..., -0.13183126,\n",
       "          0.1400934 ,  0.4951048 ]], dtype=float32),\n",
       " array([[ 0.13139689,  0.13699515, -0.18403323, ..., -0.0892983 ,\n",
       "          0.63086855,  0.11476158],\n",
       "        [ 0.31758142, -0.08494249,  0.19065702, ..., -0.1708014 ,\n",
       "          0.619709  ,  0.23720947],\n",
       "        [ 0.049652  ,  0.15342352, -0.0104103 , ..., -0.2548877 ,\n",
       "          0.46674892,  0.35060102],\n",
       "        ...,\n",
       "        [ 0.03113431,  0.08728007,  0.02436645, ..., -0.08505704,\n",
       "          0.38180107,  0.20668691],\n",
       "        [ 0.25937703,  0.12886465, -0.05183767, ..., -0.22075714,\n",
       "          0.53146976,  0.26246583],\n",
       "        [ 0.25331023,  0.22243951,  0.01043118, ..., -0.2661148 ,\n",
       "          0.35335186,  0.19150554]], dtype=float32),\n",
       " array([[ 0.10442883,  0.05054235, -0.05058983, ...,  0.04567824,\n",
       "          0.27144486,  0.20531116],\n",
       "        [ 0.08527482, -0.09265519,  0.0314783 , ..., -0.18556605,\n",
       "          0.38829476,  0.30911264],\n",
       "        [ 0.01659523,  0.11759768,  0.05551572, ..., -0.40176004,\n",
       "          0.53105235,  0.13249393],\n",
       "        ...,\n",
       "        [ 0.11532393,  0.25244564,  0.01011509, ..., -0.23153831,\n",
       "          0.38246208,  0.00935874],\n",
       "        [ 0.03030535,  0.12710847,  0.15113808, ..., -0.07772477,\n",
       "          0.18379533,  0.25610945],\n",
       "        [-0.04654093,  0.11099932, -0.07454357, ...,  0.1068237 ,\n",
       "          0.2730014 ,  0.26625568]], dtype=float32),\n",
       " array([[ 0.25096065,  0.252538  ,  0.01737791, ..., -0.2346821 ,\n",
       "          0.8321548 ,  0.25944996],\n",
       "        [-0.08287398,  0.29255804, -0.2018144 , ..., -0.2883671 ,\n",
       "          0.51267695,  0.38247514],\n",
       "        [ 0.14609618,  0.08768512, -0.11423361, ..., -0.17348292,\n",
       "          0.63280684,  0.05036415],\n",
       "        ...,\n",
       "        [-0.03952806, -0.22309002,  0.07819857, ..., -0.28742975,\n",
       "          0.41114843,  0.31990573],\n",
       "        [ 0.10999745,  0.06703968, -0.01107363, ..., -0.21502122,\n",
       "          0.32317895,  0.04701754],\n",
       "        [-0.24002132,  0.0884051 , -0.14344004, ..., -0.08478919,\n",
       "          0.50442183,  0.32487723]], dtype=float32),\n",
       " array([[ 0.12479599,  0.18613443, -0.02879068, ..., -0.11477482,\n",
       "          0.40818015,  0.34749976],\n",
       "        [-0.08307603,  0.06477653,  0.05009335, ..., -0.07838469,\n",
       "          0.29601032,  0.20164357],\n",
       "        [-0.3355134 ,  0.02886172, -0.06233223, ..., -0.28326178,\n",
       "          0.29220754,  0.14024585],\n",
       "        ...,\n",
       "        [-0.04728321,  0.11585978, -0.03934744, ..., -0.03989555,\n",
       "          0.25750396,  0.30598652],\n",
       "        [ 0.10975979,  0.21717376,  0.18143469, ..., -0.27168497,\n",
       "          0.4383908 ,  0.15818533],\n",
       "        [-0.07961226,  0.16942322,  0.1237233 , ..., -0.16435285,\n",
       "          0.33085284,  0.2949829 ]], dtype=float32),\n",
       " array([[ 0.12060414, -0.01755426,  0.0426156 , ...,  0.01197204,\n",
       "          0.3685038 ,  0.23010525],\n",
       "        [ 0.21271592,  0.19822712, -0.09583947, ...,  0.0084602 ,\n",
       "          0.49753004, -0.0355534 ],\n",
       "        [ 0.028699  ,  0.4953693 , -0.06111245, ..., -0.18784742,\n",
       "          0.45361692,  0.34942135],\n",
       "        ...,\n",
       "        [-0.15148956, -0.08496807, -0.05765608, ..., -0.03910372,\n",
       "          0.45221382,  0.3948849 ],\n",
       "        [ 0.10646853,  0.18617478, -0.00853722, ..., -0.12754941,\n",
       "          0.253704  ,  0.16753265],\n",
       "        [ 0.00523011,  0.06362842, -0.08916377, ..., -0.34341794,\n",
       "          0.5386008 ,  0.18919076]], dtype=float32),\n",
       " array([[-0.14152126, -0.09994368,  0.13525173, ..., -0.22606577,\n",
       "          0.44643575,  0.06839214],\n",
       "        [ 0.09635913,  0.13899404, -0.0601538 , ..., -0.15425706,\n",
       "          0.36260095,  0.3662659 ],\n",
       "        [ 0.09545647,  0.2478142 ,  0.04283587, ..., -0.0244275 ,\n",
       "          0.4755728 ,  0.35587734],\n",
       "        ...,\n",
       "        [-0.10757494, -0.00948262, -0.10067602, ..., -0.15885298,\n",
       "          0.6181215 ,  0.19306259],\n",
       "        [-0.01438858, -0.05321895,  0.11132854, ..., -0.46066892,\n",
       "          0.46417293,  0.20250727],\n",
       "        [ 0.12530363,  0.25384235,  0.12901479, ..., -0.29874372,\n",
       "          0.56426555,  0.22684164]], dtype=float32),\n",
       " array([[ 0.03547338,  0.01223778, -0.2886684 , ..., -0.07421545,\n",
       "          0.5472415 ,  0.09742771],\n",
       "        [ 0.20137982,  0.00790571,  0.20344457, ..., -0.03703091,\n",
       "          0.48387107,  0.26537886],\n",
       "        [ 0.07494706, -0.03099952,  0.34327704, ..., -0.03461023,\n",
       "          0.24574506,  0.26291224],\n",
       "        ...,\n",
       "        [-0.04405092,  0.13283525, -0.15737568, ..., -0.01452537,\n",
       "          0.39519083,  0.43619555],\n",
       "        [ 0.06800945,  0.07901639, -0.19545673, ..., -0.03116292,\n",
       "          0.30480793,  0.2853689 ],\n",
       "        [ 0.05862936, -0.01749035, -0.12058891, ...,  0.01107331,\n",
       "          0.4169647 ,  0.3162317 ]], dtype=float32),\n",
       " array([[-0.18007387, -0.09193356,  0.11890969, ..., -0.15785162,\n",
       "          0.38738775,  0.26054636],\n",
       "        [-0.04284562,  0.09112187,  0.14599368, ..., -0.06467178,\n",
       "          0.6627254 ,  0.21776453],\n",
       "        [ 0.03556666,  0.09614901,  0.0441411 , ..., -0.25361013,\n",
       "          0.49536523,  0.00941555],\n",
       "        ...,\n",
       "        [-0.16832714, -0.08496562,  0.19201654, ..., -0.05908014,\n",
       "          0.22467983,  0.45248622],\n",
       "        [ 0.08420037,  0.0327882 , -0.1499437 , ...,  0.08783114,\n",
       "          0.5147778 , -0.12613325],\n",
       "        [ 0.04520205,  0.11917185, -0.08246075, ..., -0.20242904,\n",
       "          0.61595714,  0.26068297]], dtype=float32),\n",
       " array([[ 0.03224862,  0.0220298 , -0.09417146, ..., -0.03445714,\n",
       "          0.3266542 ,  0.39574626],\n",
       "        [ 0.14101781, -0.01985637,  0.07585283, ..., -0.21447189,\n",
       "          0.23714924,  0.40409902],\n",
       "        [ 0.00837907,  0.3082166 ,  0.00993033, ..., -0.17198296,\n",
       "          0.5195147 ,  0.21529283],\n",
       "        ...,\n",
       "        [ 0.06601419,  0.0730752 ,  0.03896979, ..., -0.02812684,\n",
       "          0.3483189 ,  0.3460645 ],\n",
       "        [ 0.08127299,  0.31130418,  0.10590049, ..., -0.18390039,\n",
       "          0.31679368,  0.20264551],\n",
       "        [ 0.02242073,  0.07583334,  0.11070856, ..., -0.202608  ,\n",
       "          0.44071802,  0.03704409]], dtype=float32),\n",
       " array([[ 0.12501368,  0.18414545, -0.02249411, ..., -0.1244484 ,\n",
       "          0.5053634 ,  0.17204997],\n",
       "        [ 0.02852368,  0.22454129,  0.22520357, ..., -0.40333635,\n",
       "          0.5812802 ,  0.02653422],\n",
       "        [-0.10051173, -0.02794494, -0.11757877, ..., -0.1921921 ,\n",
       "          0.4960892 ,  0.19214837],\n",
       "        ...,\n",
       "        [-0.15051638, -0.06840338,  0.02346672, ..., -0.23334591,\n",
       "          0.21045394,  0.17079699],\n",
       "        [-0.0863988 , -0.06165197,  0.02737017, ..., -0.24413759,\n",
       "          0.27723956,  0.26790243],\n",
       "        [-0.2233691 , -0.13069457,  0.04228551, ..., -0.22692174,\n",
       "          0.2858756 ,  0.4829048 ]], dtype=float32),\n",
       " array([[ 0.05116247,  0.07643485,  0.10885395, ..., -0.27444333,\n",
       "          0.4506826 ,  0.14153105],\n",
       "        [-0.23185787, -0.02928499,  0.05998787, ..., -0.16661419,\n",
       "          0.471216  ,  0.3396027 ],\n",
       "        [-0.2504975 , -0.0105218 ,  0.23448242, ..., -0.12358061,\n",
       "          0.43692243,  0.43137896],\n",
       "        ...,\n",
       "        [-0.02988796,  0.16849515,  0.12800427, ..., -0.1329573 ,\n",
       "          0.24453548,  0.3276035 ],\n",
       "        [ 0.30787414,  0.06265526, -0.10586673, ..., -0.17697963,\n",
       "          0.69266057,  0.29509425],\n",
       "        [ 0.00445655, -0.22324088,  0.07089005, ..., -0.18508522,\n",
       "          0.2748717 ,  0.30560187]], dtype=float32),\n",
       " array([[ 0.05703258, -0.04760943,  0.36140454, ..., -0.46693143,\n",
       "          0.5067016 ,  0.34704238],\n",
       "        [ 0.02792621,  0.45274073,  0.03263307, ..., -0.32242316,\n",
       "          0.46309128,  0.2376412 ],\n",
       "        [-0.03175926, -0.01516022, -0.06689246, ..., -0.27345204,\n",
       "          0.6026358 , -0.03353392],\n",
       "        ...,\n",
       "        [ 0.12195234,  0.14081885, -0.2373843 , ..., -0.10984465,\n",
       "          0.2093243 ,  0.25371066],\n",
       "        [ 0.13136292, -0.00792197, -0.03919063, ..., -0.24834809,\n",
       "          0.33604518,  0.23083192],\n",
       "        [-0.02000846,  0.04965595,  0.0610735 , ..., -0.04402868,\n",
       "          0.32371023,  0.18475395]], dtype=float32),\n",
       " array([[-0.09537588,  0.0143281 , -0.02984033, ...,  0.01436325,\n",
       "          0.21965545,  0.33616358],\n",
       "        [-0.06980783,  0.21179259, -0.12685923, ..., -0.10418095,\n",
       "          0.5101099 ,  0.3243746 ],\n",
       "        [-0.02380567,  0.38985053,  0.1549465 , ..., -0.14049882,\n",
       "          0.595234  ,  0.3748379 ],\n",
       "        ...,\n",
       "        [-0.06930593, -0.00803358,  0.09099629, ..., -0.15610136,\n",
       "          0.42356747,  0.29880184],\n",
       "        [ 0.11717752,  0.04643857, -0.12991096, ..., -0.33610275,\n",
       "          0.5170588 , -0.1671431 ],\n",
       "        [-0.04265869, -0.07317169,  0.03417543, ..., -0.25471693,\n",
       "          0.4352617 ,  0.23670864]], dtype=float32),\n",
       " array([[ 0.19177638, -0.064639  ,  0.08931401, ..., -0.10825805,\n",
       "          0.61360025,  0.18173583],\n",
       "        [ 0.12477982,  0.13692439,  0.06674153, ..., -0.02053754,\n",
       "          0.38304922,  0.30362147],\n",
       "        [ 0.12327607,  0.1077102 ,  0.11160222, ..., -0.04328544,\n",
       "          0.40779305,  0.2723734 ],\n",
       "        ...,\n",
       "        [-0.24071686, -0.02479386, -0.10613829, ..., -0.21795432,\n",
       "          0.32338002,  0.3761744 ],\n",
       "        [ 0.02998239,  0.07722599,  0.0182435 , ..., -0.07290472,\n",
       "          0.33638495,  0.27838022],\n",
       "        [ 0.08011122, -0.134777  ,  0.1959721 , ..., -0.16705823,\n",
       "          0.4840599 ,  0.15677659]], dtype=float32),\n",
       " array([[ 0.01046763,  0.15180321,  0.22650948, ..., -0.03747055,\n",
       "          0.27788368,  0.34991178],\n",
       "        [-0.00777072,  0.07454231, -0.20062591, ..., -0.11161862,\n",
       "          0.27489716,  0.4955303 ],\n",
       "        [ 0.23060071, -0.06292746,  0.23039319, ..., -0.05448706,\n",
       "          0.34943423, -0.10638377],\n",
       "        ...,\n",
       "        [ 0.02764788,  0.24397667,  0.02381692, ..., -0.19559312,\n",
       "          0.3899578 ,  0.30498862],\n",
       "        [-0.02914797,  0.088343  ,  0.13038595, ..., -0.12174872,\n",
       "          0.31210548,  0.16093554],\n",
       "        [-0.06098384, -0.04786077, -0.02604884, ..., -0.16006659,\n",
       "          0.38400844,  0.63196725]], dtype=float32),\n",
       " array([[-0.15304029,  0.21644214,  0.05268381, ..., -0.10590218,\n",
       "          0.20247738,  0.3036642 ],\n",
       "        [-0.04345012,  0.00900585, -0.264404  , ..., -0.05649071,\n",
       "          0.6357381 ,  0.24939121],\n",
       "        [-0.207432  ,  0.14685532, -0.05686113, ..., -0.20896187,\n",
       "          0.653361  ,  0.22837411],\n",
       "        ...,\n",
       "        [-0.06617846,  0.10621918, -0.02592137, ..., -0.0979241 ,\n",
       "          0.28912917,  0.23453361],\n",
       "        [-0.04548702,  0.00110573,  0.00430787, ..., -0.06982922,\n",
       "          0.57343256,  0.06714423],\n",
       "        [ 0.05827495,  0.05568323, -0.05082019, ..., -0.241814  ,\n",
       "          0.12656446, -0.05565492]], dtype=float32),\n",
       " array([[-0.18120034,  0.0875299 ,  0.05854272, ..., -0.17201763,\n",
       "          0.42017636,  0.2851902 ],\n",
       "        [ 0.09823689,  0.03484114,  0.06656816, ..., -0.1068674 ,\n",
       "          0.2711922 ,  0.21188155],\n",
       "        [-0.16960222,  0.16796775, -0.5735103 , ..., -0.32219556,\n",
       "          0.33474287,  0.33822015],\n",
       "        ...,\n",
       "        [ 0.09244806, -0.11699232,  0.04006445, ...,  0.03401873,\n",
       "          0.5249503 ,  0.22185135],\n",
       "        [-0.05807798, -0.07987529, -0.08200832, ..., -0.12727728,\n",
       "          0.2555329 ,  0.39290807],\n",
       "        [ 0.00075131, -0.04147289,  0.11948332, ..., -0.144199  ,\n",
       "          0.310069  ,  0.20669822]], dtype=float32),\n",
       " array([[ 0.04167664,  0.059613  , -0.00679383, ..., -0.08807585,\n",
       "          0.3741995 ,  0.36063704],\n",
       "        [-0.07502178,  0.13515289, -0.22306342, ..., -0.17507486,\n",
       "          0.57367843,  0.32450703],\n",
       "        [ 0.0365416 ,  0.10108928,  0.12121966, ..., -0.02475486,\n",
       "          0.42399395,  0.32727832],\n",
       "        ...,\n",
       "        [-0.05462659,  0.02303845,  0.03157472, ...,  0.00601503,\n",
       "          0.25164503,  0.18797627],\n",
       "        [-0.12370143, -0.04637032,  0.01428049, ..., -0.10640999,\n",
       "          0.35385826,  0.41845784],\n",
       "        [ 0.10658813, -0.00766227, -0.02021166, ..., -0.01119555,\n",
       "          0.40929356,  0.4490206 ]], dtype=float32),\n",
       " array([[ 0.19175144, -0.13974565,  0.10436561, ..., -0.1328722 ,\n",
       "          0.49640942, -0.01786075],\n",
       "        [-0.05061937,  0.05210485,  0.00824521, ...,  0.04790272,\n",
       "          0.33489695,  0.30506063],\n",
       "        [ 0.02619731, -0.03738289,  0.08157865, ..., -0.255444  ,\n",
       "          0.3890805 ,  0.15468326],\n",
       "        ...,\n",
       "        [ 0.00752284,  0.00850543,  0.24214554, ..., -0.1605313 ,\n",
       "          0.5040813 ,  0.22861224],\n",
       "        [ 0.16460542,  0.23156074,  0.19424121, ..., -0.20687677,\n",
       "          0.35842022,  0.17555201],\n",
       "        [-0.06478719,  0.13468282, -0.19520019, ..., -0.23911507,\n",
       "          0.65114695,  0.0635559 ]], dtype=float32),\n",
       " array([[-0.01301503,  0.1262134 , -0.04361979, ..., -0.07609224,\n",
       "          0.24349602,  0.2352621 ],\n",
       "        [-0.18077154,  0.06597207,  0.13034584, ..., -0.08310428,\n",
       "          0.30391458,  0.27553064],\n",
       "        [-0.02015784,  0.15496206, -0.01006213, ..., -0.10959107,\n",
       "          0.3097888 ,  0.31455663],\n",
       "        ...,\n",
       "        [ 0.16450457,  0.09024607, -0.10087885, ..., -0.35440078,\n",
       "          0.54272825,  0.26908994],\n",
       "        [ 0.2181142 ,  0.22516239, -0.30775517, ..., -0.28204128,\n",
       "          0.7285157 ,  0.15946417],\n",
       "        [-0.04061829,  0.04333689,  0.00392037, ..., -0.02757593,\n",
       "          0.31069642,  0.28472874]], dtype=float32),\n",
       " array([[ 0.10024498,  0.04923064, -0.07224616, ..., -0.20948677,\n",
       "          0.5818558 ,  0.17143992],\n",
       "        [-0.11982347,  0.30423132, -0.03945759, ..., -0.24151699,\n",
       "          0.41791072,  0.39682811],\n",
       "        [ 0.11300278,  0.20608509, -0.3290999 , ..., -0.15788834,\n",
       "          0.54074067,  0.20422928],\n",
       "        ...,\n",
       "        [ 0.13287453,  0.00830093,  0.14387843, ..., -0.32171714,\n",
       "          0.39616817,  0.17827891],\n",
       "        [ 0.2344892 , -0.01856039, -0.35645783, ..., -0.19263068,\n",
       "          0.61999536,  0.19122799],\n",
       "        [ 0.24143451,  0.00892359,  0.00443644, ..., -0.06175605,\n",
       "          0.4907029 ,  0.09584554]], dtype=float32),\n",
       " array([[-0.0638926 , -0.02953859, -0.17558151, ..., -0.116379  ,\n",
       "          0.32752287,  0.3439379 ],\n",
       "        [ 0.08038948,  0.15516607, -0.07461984, ..., -0.01323195,\n",
       "          0.21661846,  0.29400215],\n",
       "        [ 0.03264075,  0.22881936, -0.30316836, ...,  0.01210912,\n",
       "          0.57559097,  0.37769404],\n",
       "        ...,\n",
       "        [-0.0454961 , -0.04182081, -0.04268171, ..., -0.05164669,\n",
       "          0.37036982,  0.3586326 ],\n",
       "        [-0.03089585,  0.10699505,  0.02032963, ..., -0.01197771,\n",
       "          0.46480238,  0.1500761 ],\n",
       "        [-0.07435392, -0.09899632, -0.06808224, ..., -0.14059785,\n",
       "          0.5504497 ,  0.209746  ]], dtype=float32),\n",
       " array([[-0.02997435,  0.22770037, -0.31098765, ..., -0.17742091,\n",
       "          0.5740456 ,  0.3768466 ],\n",
       "        [ 0.22101846,  0.31897104,  0.00638755, ..., -0.28327268,\n",
       "          0.7640851 ,  0.141961  ],\n",
       "        [ 0.01382549,  0.02935078, -0.08094834, ..., -0.22507441,\n",
       "          0.44040835,  0.11420457],\n",
       "        ...,\n",
       "        [ 0.07571906,  0.04351339, -0.15670855, ..., -0.1839586 ,\n",
       "          0.41761672,  0.32910302],\n",
       "        [ 0.2015533 ,  0.05981513, -0.15486467, ..., -0.2948574 ,\n",
       "          0.41663197,  0.18991649],\n",
       "        [ 0.02096772,  0.379966  ,  0.08238237, ..., -0.1277638 ,\n",
       "          0.37545866,  0.34254858]], dtype=float32),\n",
       " array([[ 0.16408059,  0.1821235 , -0.03695794, ..., -0.06355594,\n",
       "          0.4169131 ,  0.1646593 ],\n",
       "        [ 0.00492427, -0.0453061 ,  0.05672979, ..., -0.29071644,\n",
       "          0.6243753 ,  0.02378773],\n",
       "        [ 0.12666328,  0.22093739, -0.33736062, ..., -0.04140658,\n",
       "          0.50315005,  0.28139853],\n",
       "        ...,\n",
       "        [-0.03718085,  0.12094682,  0.07099999, ..., -0.2624489 ,\n",
       "          0.36439306,  0.3272287 ],\n",
       "        [-0.09679316,  0.00307355, -0.05616464, ..., -0.17741324,\n",
       "          0.2987296 ,  0.31491917],\n",
       "        [ 0.0185158 ,  0.01098294,  0.02596528, ..., -0.0851452 ,\n",
       "          0.39946994,  0.16679308]], dtype=float32),\n",
       " array([[-5.2928351e-02, -4.8686090e-01,  2.3392677e-01, ...,\n",
       "         -2.7031603e-01,  6.7995548e-02, -4.1471347e-02],\n",
       "        [ 3.3255294e-04, -5.9814556e-03,  1.1484098e-02, ...,\n",
       "         -9.7172126e-02,  2.8017557e-01,  4.7228685e-01],\n",
       "        [ 4.9366951e-02,  1.3709426e-01, -3.3547916e-02, ...,\n",
       "         -1.2910402e-01,  3.6877617e-01,  4.0656492e-01],\n",
       "        ...,\n",
       "        [ 2.5840798e-01,  6.4491138e-02, -5.2514300e-03, ...,\n",
       "         -6.0858570e-02,  4.7625005e-01,  2.6926330e-01],\n",
       "        [-1.5762345e-01, -1.0469483e-01, -5.7273269e-02, ...,\n",
       "         -1.4521794e-01,  3.2997495e-01,  3.1674933e-01],\n",
       "        [ 2.0969084e-01,  1.1529332e-01,  3.2171369e-02, ...,\n",
       "         -7.0473477e-03,  4.0949064e-01,  3.3024767e-01]], dtype=float32),\n",
       " array([[ 0.11394851,  0.0824638 , -0.23888253, ..., -0.07472392,\n",
       "          0.4574987 ,  0.15494452],\n",
       "        [ 0.30501902,  0.16759574, -0.02564729, ..., -0.13322346,\n",
       "          0.50309694,  0.20118332],\n",
       "        [-0.15151206, -0.2788768 , -0.2638058 , ..., -0.42151207,\n",
       "          0.48921862,  0.22830755],\n",
       "        ...,\n",
       "        [-0.0617225 , -0.16723783,  0.07331069, ...,  0.01456798,\n",
       "          0.14621498,  0.17698874],\n",
       "        [-0.12523061, -0.02862896,  0.26431197, ..., -0.2624388 ,\n",
       "          0.565852  ,  0.2553175 ],\n",
       "        [ 0.05319627,  0.0510079 , -0.25349516, ..., -0.5676706 ,\n",
       "          0.5536943 ,  0.24919088]], dtype=float32),\n",
       " array([[ 0.00382052,  0.13899457, -0.08836259, ..., -0.22566406,\n",
       "          0.5768997 ,  0.33345824],\n",
       "        [-0.90055937,  0.20802449,  0.33730072, ...,  0.06602662,\n",
       "          0.4757978 ,  0.44228774],\n",
       "        [ 0.05998038, -0.04032373,  0.10117696, ..., -0.2206869 ,\n",
       "          0.40686962,  0.24986257],\n",
       "        ...,\n",
       "        [-0.25955012,  0.11577361,  0.19391823, ..., -0.45693806,\n",
       "          0.27888423,  0.21040107],\n",
       "        [-0.08772299,  0.02794137, -0.039078  , ..., -0.05130888,\n",
       "          0.27097976,  0.22133112],\n",
       "        [ 0.47982103,  0.31163493, -0.20022355, ..., -0.0713669 ,\n",
       "          0.54844886, -0.14983182]], dtype=float32),\n",
       " array([[ 0.12636186,  0.11227246, -0.15360697, ..., -0.02255543,\n",
       "          0.655126  ,  0.27577055],\n",
       "        [ 0.01022911, -0.17103803,  0.2444143 , ..., -0.22979045,\n",
       "          0.62968504,  0.15316644],\n",
       "        [ 0.00066044, -0.15053968,  0.11883014, ..., -0.24409883,\n",
       "          0.46238315,  0.14898403],\n",
       "        ...,\n",
       "        [ 0.03173232,  0.02448357,  0.04762888, ..., -0.13494925,\n",
       "          0.5375098 ,  0.08859431],\n",
       "        [-0.2864145 , -0.05509835,  0.19669504, ..., -0.36619544,\n",
       "          0.47163028,  0.36107373],\n",
       "        [ 0.08444361,  0.09159634,  0.04624988, ..., -0.10831471,\n",
       "          0.58113605,  0.27027974]], dtype=float32),\n",
       " array([[ 0.2516498 ,  0.07040824,  0.11051369, ..., -0.30975598,\n",
       "          0.5092189 ,  0.13830252],\n",
       "        [ 0.09427644,  0.08354259, -0.03015792, ..., -0.13005641,\n",
       "          0.39462632,  0.21586925],\n",
       "        [ 0.06235797, -0.03056184, -0.0271844 , ..., -0.19730856,\n",
       "          0.73453075,  0.3549433 ],\n",
       "        ...,\n",
       "        [ 0.03765289, -0.04114668,  0.02885057, ..., -0.10076261,\n",
       "          0.43524057,  0.34020114],\n",
       "        [-0.04794434, -0.1412529 ,  0.01304683, ..., -0.17754667,\n",
       "          0.33905873,  0.30779624],\n",
       "        [ 0.07389161,  0.0918473 , -0.13797252, ..., -0.08876754,\n",
       "          0.55642426,  0.41426644]], dtype=float32),\n",
       " array([[ 0.05295328,  0.20394483, -0.19600208, ..., -0.12157653,\n",
       "          0.536155  ,  0.2558362 ],\n",
       "        [ 0.10937768,  0.10699761,  0.0237186 , ..., -0.19274507,\n",
       "          0.3962309 ,  0.08564667],\n",
       "        [-0.07437212,  0.11138994,  0.08889204, ..., -0.2617814 ,\n",
       "          0.32634145,  0.23163573],\n",
       "        ...,\n",
       "        [ 0.27424696,  0.28029746,  0.08872901, ..., -0.13660967,\n",
       "          0.3701233 ,  0.2582858 ],\n",
       "        [ 0.00298583,  0.1182488 , -0.21226169, ..., -0.20317566,\n",
       "          0.4730934 ,  0.24240987],\n",
       "        [ 0.01338768,  0.00617576,  0.20200099, ..., -0.22712184,\n",
       "          0.069025  ,  0.32548448]], dtype=float32),\n",
       " array([[ 0.0336504 ,  0.03568801,  0.11775564, ..., -0.33531097,\n",
       "          0.38914964,  0.07841831],\n",
       "        [ 0.13785622,  0.10145485, -0.10995911, ..., -0.13518052,\n",
       "          0.37111747,  0.17799237],\n",
       "        [ 0.13371155,  0.12336212,  0.05752825, ..., -0.17340761,\n",
       "          0.48804837,  0.00817272],\n",
       "        ...,\n",
       "        [ 0.07886648,  0.09112953,  0.24515101, ..., -0.16681267,\n",
       "          0.51353854, -0.02545074],\n",
       "        [ 0.05918964,  0.0867023 ,  0.09094843, ..., -0.15629013,\n",
       "          0.21272689,  0.17483339],\n",
       "        [-0.0424191 ,  0.1672087 ,  0.12269507, ..., -0.05039803,\n",
       "          0.28121617,  0.24838524]], dtype=float32),\n",
       " array([[-0.06319536,  0.05866037, -0.10079157, ..., -0.18847892,\n",
       "          0.29086056,  0.33274275],\n",
       "        [-0.05890009,  0.02533236,  0.15427306, ..., -0.1120269 ,\n",
       "          0.3591325 ,  0.6148099 ],\n",
       "        [-0.02748364, -0.17444019,  0.16618459, ..., -0.20768619,\n",
       "          0.43320614,  0.19609183],\n",
       "        ...,\n",
       "        [ 0.16418545,  0.27447516,  0.03691009, ..., -0.19364846,\n",
       "          0.4515684 ,  0.16959774],\n",
       "        [-0.3060892 , -0.23783268,  0.07840844, ..., -0.09733798,\n",
       "          0.0873294 ,  0.4822997 ],\n",
       "        [ 0.23070905,  0.10420445, -0.03817404, ..., -0.24622117,\n",
       "          0.3412782 ,  0.34108627]], dtype=float32),\n",
       " array([[-0.00851542,  0.13908558,  0.07503265, ..., -0.27543977,\n",
       "          0.30910924,  0.1101283 ],\n",
       "        [-0.03430425, -0.02485267, -0.03386637, ..., -0.07759278,\n",
       "          0.31039286,  0.41110426],\n",
       "        [-0.02332504, -0.04640786, -0.07447982, ..., -0.24325047,\n",
       "          0.59269035,  0.07216947],\n",
       "        ...,\n",
       "        [ 0.3094289 ,  0.14121808,  0.19254215, ..., -0.00862211,\n",
       "          0.49124348,  0.3035095 ],\n",
       "        [-0.12854722,  0.03920338, -0.14847541, ..., -0.15506367,\n",
       "          0.41562685,  0.40418574],\n",
       "        [ 0.38468722,  0.17608707, -0.15486188, ..., -0.16940467,\n",
       "          0.6065053 ,  0.16308257]], dtype=float32),\n",
       " array([[-0.09769503,  0.24765538, -0.13170114, ..., -0.2015628 ,\n",
       "          0.29204485,  0.23987453],\n",
       "        [ 0.03455251, -0.14475618,  0.3527881 , ..., -0.06470162,\n",
       "          0.4113833 ,  0.21004738],\n",
       "        [-0.13672337,  0.08280905, -0.16592698, ..., -0.19065067,\n",
       "          0.43727016,  0.38226932],\n",
       "        ...,\n",
       "        [ 0.04191147,  0.37218684, -0.00084688, ..., -0.35861588,\n",
       "          0.60084295, -0.04583113],\n",
       "        [ 0.10114573,  0.20929457, -0.28092003, ..., -0.08178529,\n",
       "          0.47340015,  0.20949739],\n",
       "        [-0.02342943,  0.09955332,  0.04032183, ..., -0.09350207,\n",
       "          0.78153884,  0.1884016 ]], dtype=float32),\n",
       " array([[ 0.01781513,  0.13404813,  0.10253374, ..., -0.12879165,\n",
       "          0.25565717,  0.19409989],\n",
       "        [ 0.00634236,  0.28616735,  0.0517998 , ..., -0.21611975,\n",
       "          0.5836451 ,  0.3475889 ],\n",
       "        [ 0.13675989,  0.18206896,  0.02924496, ..., -0.05076687,\n",
       "          0.35412106,  0.3607188 ],\n",
       "        ...,\n",
       "        [ 0.0578441 ,  0.0747485 ,  0.11103874, ..., -0.09800462,\n",
       "          0.45011222,  0.2729602 ],\n",
       "        [-0.05862168,  0.0280095 , -0.13043095, ..., -0.12803373,\n",
       "          0.18272656,  0.43410358],\n",
       "        [ 0.17414764, -0.1376364 ,  0.04882532, ..., -0.2043356 ,\n",
       "          0.544522  ,  0.01566682]], dtype=float32),\n",
       " array([[-0.01907177, -0.12271459,  0.03897558, ..., -0.09770948,\n",
       "          0.3427912 ,  0.41716188],\n",
       "        [-0.04886033,  0.27931246, -0.16603053, ..., -0.15429592,\n",
       "          0.07761391,  0.3802851 ],\n",
       "        [ 0.02122686, -0.18468103,  0.07895869, ..., -0.21565291,\n",
       "          0.28128085,  0.11214463],\n",
       "        ...,\n",
       "        [ 0.09647776,  0.01011932, -0.10522881, ..., -0.241476  ,\n",
       "          0.53982484,  0.16891952],\n",
       "        [ 0.0432441 ,  0.13524534,  0.03625361, ...,  0.09256556,\n",
       "          0.47669458,  0.22693099],\n",
       "        [-0.34282756,  0.2244357 ,  0.13404353, ..., -0.0531047 ,\n",
       "          0.31702068,  0.4976123 ]], dtype=float32),\n",
       " array([[ 0.08032733,  0.27222523, -0.20060353, ..., -0.11012905,\n",
       "          0.42431024,  0.37285304],\n",
       "        [ 0.05682173,  0.05230823,  0.15057194, ..., -0.22933432,\n",
       "          0.2504949 ,  0.12776852],\n",
       "        [-0.24833383, -0.10275942,  0.15856822, ..., -0.1610283 ,\n",
       "          0.2475311 ,  0.42398825],\n",
       "        ...,\n",
       "        [ 0.30299008,  0.07943626,  0.07903089, ..., -0.34901097,\n",
       "          0.44069737,  0.12100762],\n",
       "        [-0.14847296,  0.10203497, -0.07250193, ..., -0.02028141,\n",
       "          0.3962501 ,  0.19875613],\n",
       "        [ 0.01596506, -0.18728349,  0.02019158, ..., -0.24260743,\n",
       "          0.2373719 ,  0.35201272]], dtype=float32),\n",
       " array([[-0.01966051,  0.03525687, -0.0635076 , ..., -0.00443573,\n",
       "          0.34003463,  0.30009055],\n",
       "        [-0.02158186,  0.07094084, -0.2856347 , ..., -0.0522893 ,\n",
       "          0.4071099 ,  0.0909524 ],\n",
       "        [ 0.16722517, -0.11683868,  0.05644984, ..., -0.06543528,\n",
       "          0.2769963 ,  0.13353074],\n",
       "        ...,\n",
       "        [ 0.13731486,  0.53114337, -0.16725919, ..., -0.20054595,\n",
       "          0.59974056,  0.28392175],\n",
       "        [ 0.05089133, -0.06022979,  0.04745279, ..., -0.1637221 ,\n",
       "          0.3092671 ,  0.34415394],\n",
       "        [ 0.0550581 ,  0.18258043,  0.00654139, ..., -0.00876234,\n",
       "          0.46209982,  0.10224231]], dtype=float32),\n",
       " array([[ 0.23067296,  0.23645289, -0.18610208, ..., -0.0796956 ,\n",
       "          0.3888339 ,  0.11314604],\n",
       "        [-0.03467315,  0.18831852, -0.00143933, ..., -0.23494776,\n",
       "          0.24239461,  0.14829229],\n",
       "        [ 0.01392211, -0.03908811, -0.28453225, ..., -0.23041324,\n",
       "          0.43636614,  0.3995399 ],\n",
       "        ...,\n",
       "        [-0.01463512,  0.0914416 ,  0.16703737, ..., -0.30227175,\n",
       "          0.54894793,  0.30321303],\n",
       "        [ 0.05678993,  0.06745192,  0.12730807, ..., -0.05204195,\n",
       "          0.3870722 ,  0.1956604 ],\n",
       "        [-0.06633638,  0.03632215, -0.6010382 , ..., -0.128144  ,\n",
       "          0.22750871,  0.5441396 ]], dtype=float32),\n",
       " array([[ 0.1323014 ,  0.16480783, -0.12349348, ..., -0.05116186,\n",
       "          0.4519297 ,  0.19338484],\n",
       "        [-0.02339389,  0.1486478 ,  0.01555438, ..., -0.2235961 ,\n",
       "          0.32158017,  0.06128589],\n",
       "        [ 0.2618254 ,  0.08763243, -0.01202703, ..., -0.24406756,\n",
       "          0.52729523, -0.01270968],\n",
       "        ...,\n",
       "        [ 0.02156112,  0.21411292,  0.09012919, ..., -0.1035892 ,\n",
       "          0.5546697 ,  0.58028626],\n",
       "        [ 0.10535575, -0.04442293, -0.05795172, ..., -0.06827741,\n",
       "          0.6978459 ,  0.3430812 ],\n",
       "        [ 0.29514846,  0.22978246,  0.02702446, ..., -0.13985813,\n",
       "          0.5256022 ,  0.2905998 ]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузим предобученную модель и преобразуем ей наш датасет в векторные представления - embedding'и\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4387660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получилась солжная таблица состоящая из списка матриц, присоединим все эти матрицы друг к другу при помощи конкатенации и поделим их\n",
    "#на тестовую с обучающей выборки\n",
    "bert_features = np.concatenate(embeddings)\n",
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(bert_features,\n",
    "                                                                                               target_downsampled,\n",
    "                                                                                               test_size=.25,\n",
    "                                                                                               random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "023520eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948073701842546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучим логистическую регрессию на полученной натрицу, сделаем предсказание по обучающих фичах и снимем метрику\n",
    "model_LR_bert = LogisticRegression(random_state=12, max_iter=521, C=4, solver='liblinear', penalty='l1')\n",
    "model_LR_bert.fit(features_train_bert, target_train_bert)\n",
    "predictions_bert = model_LR_bert.predict(features_train_bert)\n",
    "\n",
    "\n",
    "f1_score(target_train_bert, predictions_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b761f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45901639344262296"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучим логистическую регрессию на полученной натрицу, сделаем предсказание по тестовых фичах и снимем метрику\n",
    "model_LR_bert = LogisticRegression(random_state=12, max_iter=521, C=4, solver='liblinear', penalty='l1')\n",
    "model_LR_bert.fit(features_train_bert, target_train_bert)\n",
    "predictions_bert = model_LR_bert.predict(features_test_bert)\n",
    "\n",
    "\n",
    "f1_score(target_test_bert, predictions_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd608b6",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "Лучше всех себя показала логистическая регрессия с гиперпараметрами подобранными RandomizedSearch'ем.\n",
    "Снять хорошую метрику с Bert не получилось в силу ограниченности ресурсов, при подаче больше тысячи объектов для обработки ядро в юпитере умирало. Пришлось очень сильно урезать выборку, чтобы домашняя машина смогла переварить этого Microsoft-овского зверя."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 49,
    "start_time": "2022-07-25T22:13:55.689Z"
   },
   {
    "duration": 3819,
    "start_time": "2022-07-26T06:45:51.325Z"
   },
   {
    "duration": 45,
    "start_time": "2022-07-26T20:26:45.197Z"
   },
   {
    "duration": 2387,
    "start_time": "2022-07-26T20:27:05.532Z"
   },
   {
    "duration": 2131,
    "start_time": "2022-07-26T20:27:07.921Z"
   },
   {
    "duration": 3161,
    "start_time": "2022-07-26T20:27:10.055Z"
   },
   {
    "duration": 49071,
    "start_time": "2022-07-26T20:27:13.217Z"
   },
   {
    "duration": 334,
    "start_time": "2022-07-26T20:28:36.144Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
